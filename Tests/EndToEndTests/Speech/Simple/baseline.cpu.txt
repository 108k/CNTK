CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu DeviceId=-1 timestamping=true forceDeterministicAlgorithms=true makeMode=true
CNTK 2.3.1+ (HEAD f4f0f8, Dec 11 2017 18:34:12) at 2017/12/12 17:01:10

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  forceDeterministicAlgorithms=true  makeMode=true
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
12/12/2017 17:01:10: -------------------------------------------------------------------
12/12/2017 17:01:10: Build info: 

12/12/2017 17:01:10: 		Built time: Dec 11 2017 18:28:39
12/12/2017 17:01:10: 		Last modified date: Wed Nov 15 09:27:10 2017
12/12/2017 17:01:10: 		Build type: release
12/12/2017 17:01:10: 		Build target: GPU
12/12/2017 17:01:10: 		With 1bit-SGD: yes
12/12/2017 17:01:10: 		With ASGD: yes
12/12/2017 17:01:10: 		Math lib: mkl
12/12/2017 17:01:10: 		CUDA version: 9.0.0
12/12/2017 17:01:10: 		CUDNN version: 7.0.4
12/12/2017 17:01:10: 		Build Branch: HEAD
12/12/2017 17:01:10: 		Build SHA1: f4f0f82eabcc482dbd03af1f946a44ae2b8b97bf
12/12/2017 17:01:10: 		MPI distribution: Open MPI
12/12/2017 17:01:10: 		MPI version: 1.10.7
12/12/2017 17:01:10: -------------------------------------------------------------------
12/12/2017 17:01:10: -------------------------------------------------------------------
12/12/2017 17:01:10: GPU info:

12/12/2017 17:01:10: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/12/2017 17:01:10: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:forceDeterministicAlgorithms=true
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
12/12/2017 17:01:10: Commands: Simple_Demo Simple_Demo_Output
12/12/2017 17:01:10: precision = "float"
12/12/2017 17:01:10: WARNING: forceDeterministicAlgorithms flag is specified. Using 1 CPU thread for processing.

12/12/2017 17:01:10: ##############################################################################
12/12/2017 17:01:10: #                                                                            #
12/12/2017 17:01:10: # Simple_Demo command (train action)                                         #
12/12/2017 17:01:10: #                                                                            #
12/12/2017 17:01:10: ##############################################################################

12/12/2017 17:01:10: 
Creating virgin network.
SimpleNetworkBuilder Using CPU
12/12/2017 17:01:10: 
Model has 25 nodes. Using CPU.

12/12/2017 17:01:10: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
12/12/2017 17:01:10: Evaluation criterion: EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 4 are aliased.
	W2*H1 (gradient) reuses HLast (gradient)
	W1*H1 (gradient) reuses W1*H1+B1 (gradient)

Memory Sharing: Out of 40 matrices, 21 are shared as 5, and 19 are not shared.

Here are the ones that share memory:
	{ PosteriorProb : [2 x 1 x *]
	  ScaledLogLikelihood : [2 x 1 x *] }
	{ HLast : [2 x 1 x *] (gradient)
	  W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *]
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *]
	  W2*H1 : [2 x 1 x *] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *] }
	{ H2 : [50 x 1 x *]
	  W0*features+B0 : [50 x 1 x *]
	  W1 : [50 x 50] (gradient)
	  W1*H1 : [50 x 1 x *] }
	{ H1 : [50 x 1 x *] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *]
	  W0*features : [50 x *]
	  W0*features : [50 x *] (gradient) }

Here are the ones that don't share memory:
	{features : [2 x *]}
	{InvStdOfFeatures : [2]}
	{MeanOfFeatures : [2]}
	{W0 : [50 x 2]}
	{B0 : [50 x 1]}
	{W1 : [50 x 50]}
	{B1 : [50 x 1]}
	{W2 : [2 x 50]}
	{B2 : [2 x 1]}
	{labels : [2 x *]}
	{Prior : [2]}
	{EvalClassificationError : [1]}
	{CrossEntropyWithSoftmax : [1]}
	{LogOfPrior : [2]}
	{CrossEntropyWithSoftmax : [1] (gradient)}
	{MVNormalizedFeatures : [2 x *]}
	{B2 : [2 x 1] (gradient)}
	{B1 : [50 x 1] (gradient)}
	{W2 : [2 x 50] (gradient)}


12/12/2017 17:01:10: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

12/12/2017 17:01:10: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
12/12/2017 17:01:10: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
12/12/2017 17:01:10: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
12/12/2017 17:01:10: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
12/12/2017 17:01:10: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
12/12/2017 17:01:10: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


12/12/2017 17:01:10: Precomputing --> 3 PreCompute nodes found.

12/12/2017 17:01:10: 	MeanOfFeatures = Mean()
12/12/2017 17:01:10: 	InvStdOfFeatures = InvStdDev()
12/12/2017 17:01:10: 	Prior = Mean()

12/12/2017 17:01:10: Precomputing --> Completed.


12/12/2017 17:01:10: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:10: Starting minibatch loop.
12/12/2017 17:01:10:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.82292490 * 1280; EvalClassificationError = 0.51875000 * 1280; time = 0.0140s; samplesPerSecond = 91551.5
12/12/2017 17:01:10:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.77976751 * 1280; EvalClassificationError = 0.50781250 * 1280; time = 0.0076s; samplesPerSecond = 169498.3
12/12/2017 17:01:10:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.72312775 * 1280; EvalClassificationError = 0.48828125 * 1280; time = 0.0072s; samplesPerSecond = 178820.9
12/12/2017 17:01:10:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.71024914 * 1280; EvalClassificationError = 0.51484375 * 1280; time = 0.0079s; samplesPerSecond = 162955.6
12/12/2017 17:01:10:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.69842205 * 1280; EvalClassificationError = 0.50078125 * 1280; time = 0.0069s; samplesPerSecond = 185292.4
12/12/2017 17:01:10:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.71133003 * 1280; EvalClassificationError = 0.50781250 * 1280; time = 0.0080s; samplesPerSecond = 160562.0
12/12/2017 17:01:10:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.70956345 * 1280; EvalClassificationError = 0.50156250 * 1280; time = 0.0075s; samplesPerSecond = 169817.6
12/12/2017 17:01:10: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.73301484 * 10000; EvalClassificationError = 0.50560000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.065918s
12/12/2017 17:01:10: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.1'

12/12/2017 17:01:10: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:10: Starting minibatch loop.
12/12/2017 17:01:10:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70886803 * 1280; EvalClassificationError = 0.49296875 * 1280; time = 0.0093s; samplesPerSecond = 137112.5
12/12/2017 17:01:10:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.74700861 * 1280; EvalClassificationError = 0.46406250 * 1280; time = 0.0073s; samplesPerSecond = 174301.4
12/12/2017 17:01:10:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.74863882 * 1280; EvalClassificationError = 0.51171875 * 1280; time = 0.0071s; samplesPerSecond = 180152.3
12/12/2017 17:01:10:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.74191227 * 1280; EvalClassificationError = 0.49140625 * 1280; time = 0.0072s; samplesPerSecond = 178315.2
12/12/2017 17:01:10:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.70860653 * 1280; EvalClassificationError = 0.44843750 * 1280; time = 0.0069s; samplesPerSecond = 185469.6
12/12/2017 17:01:10:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.53536186 * 1280; EvalClassificationError = 0.27968750 * 1280; time = 0.0073s; samplesPerSecond = 175457.8
12/12/2017 17:01:10:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.21460953 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0069s; samplesPerSecond = 184720.2
12/12/2017 17:01:10: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.58242163 * 10000; EvalClassificationError = 0.36300000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.0599291s
12/12/2017 17:01:10: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.2'

12/12/2017 17:01:10: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:10: Starting minibatch loop.
12/12/2017 17:01:10:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.22909741 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0088s; samplesPerSecond = 146002.1
12/12/2017 17:01:10:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.23779507 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0075s; samplesPerSecond = 170312.4
12/12/2017 17:01:10:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20464730 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0071s; samplesPerSecond = 180208.1
12/12/2017 17:01:10:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.22728739 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0073s; samplesPerSecond = 174551.0
12/12/2017 17:01:10:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19903393 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0075s; samplesPerSecond = 171471.4
12/12/2017 17:01:10:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18024931 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0076s; samplesPerSecond = 167901.9
12/12/2017 17:01:10:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16613731 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0071s; samplesPerSecond = 180821.6
12/12/2017 17:01:10: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.20095585 * 10000; EvalClassificationError = 0.07710000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.0602457s
12/12/2017 17:01:10: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.3'

12/12/2017 17:01:10: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:10: Starting minibatch loop.
12/12/2017 17:01:10:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14966836 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0073s; samplesPerSecond = 174830.0
12/12/2017 17:01:10:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17832897 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0070s; samplesPerSecond = 183449.4
12/12/2017 17:01:10:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17099302 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0087s; samplesPerSecond = 146356.0
12/12/2017 17:01:10:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20656900 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0072s; samplesPerSecond = 177440.1
12/12/2017 17:01:10:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18621626 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0160s; samplesPerSecond = 80180.9
12/12/2017 17:01:10:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16608057 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0073s; samplesPerSecond = 174486.8
12/12/2017 17:01:10:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17945175 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0070s; samplesPerSecond = 184066.7
12/12/2017 17:01:10: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.17554486 * 10000; EvalClassificationError = 0.07780000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.0686112s
12/12/2017 17:01:10: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.4'

12/12/2017 17:01:10: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:10: Starting minibatch loop.
12/12/2017 17:01:10:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16107520 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0072s; samplesPerSecond = 177548.4
12/12/2017 17:01:10:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17703077 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0075s; samplesPerSecond = 170353.2
12/12/2017 17:01:10:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16816339 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0077s; samplesPerSecond = 165584.3
12/12/2017 17:01:10:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16302919 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0079s; samplesPerSecond = 161069.1
12/12/2017 17:01:10:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18440590 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0085s; samplesPerSecond = 149976.0
12/12/2017 17:01:10:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17460718 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0077s; samplesPerSecond = 166573.4
12/12/2017 17:01:11:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17822256 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0075s; samplesPerSecond = 170682.6
12/12/2017 17:01:11: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16998136 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.0626991s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.5'

12/12/2017 17:01:11: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17073443 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0072s; samplesPerSecond = 178613.8
12/12/2017 17:01:11:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19877708 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0101s; samplesPerSecond = 126536.0
12/12/2017 17:01:11:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17885036 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0079s; samplesPerSecond = 161873.7
12/12/2017 17:01:11:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17260804 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0071s; samplesPerSecond = 181272.3
12/12/2017 17:01:11:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18293109 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0074s; samplesPerSecond = 173289.1
12/12/2017 17:01:11:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17321157 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0069s; samplesPerSecond = 185908.7
12/12/2017 17:01:11:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.20213823 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0070s; samplesPerSecond = 182022.4
12/12/2017 17:01:11: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.18083223 * 10000; EvalClassificationError = 0.08030000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.0616031s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.6'

12/12/2017 17:01:11: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19412365 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0107s; samplesPerSecond = 119758.2
12/12/2017 17:01:11:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17305024 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0071s; samplesPerSecond = 180291.8
12/12/2017 17:01:11:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18252103 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0073s; samplesPerSecond = 174572.4
12/12/2017 17:01:11:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14360762 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0076s; samplesPerSecond = 168367.9
12/12/2017 17:01:11:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14654026 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0072s; samplesPerSecond = 177543.5
12/12/2017 17:01:11:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17601814 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0075s; samplesPerSecond = 169653.3
12/12/2017 17:01:11:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17026110 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0071s; samplesPerSecond = 179279.2
12/12/2017 17:01:11: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.17132515 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.0623279s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.7'

12/12/2017 17:01:11: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18865138 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0083s; samplesPerSecond = 153848.0
12/12/2017 17:01:11:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17957422 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0071s; samplesPerSecond = 179939.6
12/12/2017 17:01:11:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17792881 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0075s; samplesPerSecond = 170953.9
12/12/2017 17:01:11:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16580181 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0073s; samplesPerSecond = 175095.4
12/12/2017 17:01:11:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17047377 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0069s; samplesPerSecond = 184858.9
12/12/2017 17:01:11:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19055262 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0073s; samplesPerSecond = 175925.7
12/12/2017 17:01:11:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15224190 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0072s; samplesPerSecond = 178529.1
12/12/2017 17:01:11: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.17549961 * 10000; EvalClassificationError = 0.08040000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.0607134s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.8'

12/12/2017 17:01:11: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20850582 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0075s; samplesPerSecond = 171800.6
12/12/2017 17:01:11:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20732808 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0074s; samplesPerSecond = 173317.3
12/12/2017 17:01:11:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18902955 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0070s; samplesPerSecond = 183781.3
12/12/2017 17:01:11:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19406590 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0098s; samplesPerSecond = 130617.6
12/12/2017 17:01:11:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17629342 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0071s; samplesPerSecond = 181251.8
12/12/2017 17:01:11:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15011091 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0074s; samplesPerSecond = 172309.3
12/12/2017 17:01:11:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15326128 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0071s; samplesPerSecond = 180274.1
12/12/2017 17:01:11: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.18179957 * 10000; EvalClassificationError = 0.07810000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.0612158s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.9'

12/12/2017 17:01:11: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16430739 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0072s; samplesPerSecond = 176761.4
12/12/2017 17:01:11:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15331808 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0074s; samplesPerSecond = 173253.9
12/12/2017 17:01:11:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17684612 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0097s; samplesPerSecond = 132560.1
12/12/2017 17:01:11:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17414093 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0073s; samplesPerSecond = 176303.7
12/12/2017 17:01:11:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19192309 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0094s; samplesPerSecond = 135508.5
12/12/2017 17:01:11:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15996084 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0073s; samplesPerSecond = 175424.2
12/12/2017 17:01:11:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15455036 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0071s; samplesPerSecond = 179422.5
12/12/2017 17:01:11: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.16562637 * 10000; EvalClassificationError = 0.07510000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.0634543s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.10'

12/12/2017 17:01:11: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16918753 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0074s; samplesPerSecond = 173096.9
12/12/2017 17:01:11:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15994176 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0090s; samplesPerSecond = 142418.4
12/12/2017 17:01:11:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17205522 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0070s; samplesPerSecond = 182789.2
12/12/2017 17:01:11:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16319308 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0070s; samplesPerSecond = 183528.3
12/12/2017 17:01:11:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15153399 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0071s; samplesPerSecond = 180383.3
12/12/2017 17:01:11:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15329256 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0077s; samplesPerSecond = 165599.3
12/12/2017 17:01:11:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15840330 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0071s; samplesPerSecond = 179417.5
12/12/2017 17:01:11: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16564066 * 10000; EvalClassificationError = 0.07490000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.0602683s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.11'

12/12/2017 17:01:11: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16317611 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0095s; samplesPerSecond = 134554.1
12/12/2017 17:01:11:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17073984 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0071s; samplesPerSecond = 180342.7
12/12/2017 17:01:11:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17058744 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0071s; samplesPerSecond = 180987.8
12/12/2017 17:01:11:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16312737 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0073s; samplesPerSecond = 175198.5
12/12/2017 17:01:11:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15805616 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0072s; samplesPerSecond = 177010.7
12/12/2017 17:01:11:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16143808 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0075s; samplesPerSecond = 171006.4
12/12/2017 17:01:11:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14267263 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0071s; samplesPerSecond = 180998.0
12/12/2017 17:01:11: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16131625 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.0603615s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.12'

12/12/2017 17:01:11: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14920791 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0070s; samplesPerSecond = 181668.5
12/12/2017 17:01:11:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18176967 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0072s; samplesPerSecond = 178282.9
12/12/2017 17:01:11:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17360950 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0070s; samplesPerSecond = 182030.2
12/12/2017 17:01:11:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15493855 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0077s; samplesPerSecond = 167121.5
12/12/2017 17:01:11:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15254560 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0070s; samplesPerSecond = 183607.3
12/12/2017 17:01:11:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17198849 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0075s; samplesPerSecond = 170587.1
12/12/2017 17:01:11:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15650845 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0070s; samplesPerSecond = 181944.8
12/12/2017 17:01:11: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16411056 * 10000; EvalClassificationError = 0.07390000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.0579958s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.13'

12/12/2017 17:01:11: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18764360 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0072s; samplesPerSecond = 178384.8
12/12/2017 17:01:11:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19377413 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0078s; samplesPerSecond = 164806.2
12/12/2017 17:01:11:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15803921 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0070s; samplesPerSecond = 183320.7
12/12/2017 17:01:11:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18707128 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0083s; samplesPerSecond = 154470.0
12/12/2017 17:01:11:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17851605 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0079s; samplesPerSecond = 161420.5
12/12/2017 17:01:11:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15969305 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0091s; samplesPerSecond = 140218.7
12/12/2017 17:01:11:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15674286 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0075s; samplesPerSecond = 170419.0
12/12/2017 17:01:11: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.17456859 * 10000; EvalClassificationError = 0.07970000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.0626055s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.14'

12/12/2017 17:01:11: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16807175 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0074s; samplesPerSecond = 172281.5
12/12/2017 17:01:11:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14487228 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0075s; samplesPerSecond = 169860.4
12/12/2017 17:01:11:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16922979 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0078s; samplesPerSecond = 165035.7
12/12/2017 17:01:11:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16383829 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0088s; samplesPerSecond = 145593.5
12/12/2017 17:01:11:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16629257 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0069s; samplesPerSecond = 184853.6
12/12/2017 17:01:11:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16055632 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0079s; samplesPerSecond = 161659.0
12/12/2017 17:01:11:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15666056 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0072s; samplesPerSecond = 177913.7
12/12/2017 17:01:11: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16106023 * 10000; EvalClassificationError = 0.07400000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.0611252s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.15'

12/12/2017 17:01:11: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16057007 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0084s; samplesPerSecond = 153071.6
12/12/2017 17:01:11:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15552270 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0083s; samplesPerSecond = 154354.5
12/12/2017 17:01:11:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16812935 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0077s; samplesPerSecond = 166951.4
12/12/2017 17:01:11:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16662087 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0074s; samplesPerSecond = 173958.0
12/12/2017 17:01:11:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18013902 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0070s; samplesPerSecond = 182401.1
12/12/2017 17:01:11:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16758642 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0090s; samplesPerSecond = 142585.0
12/12/2017 17:01:11:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17382116 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0072s; samplesPerSecond = 177410.6
12/12/2017 17:01:11: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.16673329 * 10000; EvalClassificationError = 0.07770000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.0622786s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.16'

12/12/2017 17:01:11: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15741985 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0096s; samplesPerSecond = 132860.0
12/12/2017 17:01:11:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16492169 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0074s; samplesPerSecond = 172630.0
12/12/2017 17:01:11:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18577290 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0090s; samplesPerSecond = 142127.5
12/12/2017 17:01:11:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16102147 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0077s; samplesPerSecond = 166087.1
12/12/2017 17:01:11:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15495439 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0074s; samplesPerSecond = 173385.3
12/12/2017 17:01:11:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15126562 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0076s; samplesPerSecond = 168401.1
12/12/2017 17:01:11:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15345888 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0070s; samplesPerSecond = 183163.3
12/12/2017 17:01:11: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.16122594 * 10000; EvalClassificationError = 0.07560000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.0641549s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.17'

12/12/2017 17:01:11: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15050418 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0078s; samplesPerSecond = 164835.9
12/12/2017 17:01:11:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16195531 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0074s; samplesPerSecond = 173228.1
12/12/2017 17:01:11:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16647623 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0092s; samplesPerSecond = 138935.6
12/12/2017 17:01:11:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15378647 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0074s; samplesPerSecond = 173352.5
12/12/2017 17:01:11:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14804454 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0073s; samplesPerSecond = 174420.2
12/12/2017 17:01:11:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15810256 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0076s; samplesPerSecond = 169258.4
12/12/2017 17:01:11:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15576067 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0073s; samplesPerSecond = 176083.0
12/12/2017 17:01:11: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15669077 * 10000; EvalClassificationError = 0.07460000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.0621314s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.18'

12/12/2017 17:01:11: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15712049 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0073s; samplesPerSecond = 175059.5
12/12/2017 17:01:11:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14908137 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0097s; samplesPerSecond = 132327.1
12/12/2017 17:01:11:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16572506 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0073s; samplesPerSecond = 176184.8
12/12/2017 17:01:11:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14920230 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0082s; samplesPerSecond = 155924.5
12/12/2017 17:01:11:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17894840 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0091s; samplesPerSecond = 140332.4
12/12/2017 17:01:11:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16354027 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0072s; samplesPerSecond = 176846.9
12/12/2017 17:01:11:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17957916 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0072s; samplesPerSecond = 177047.5
12/12/2017 17:01:11: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16370311 * 10000; EvalClassificationError = 0.07820000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.0633056s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.19'

12/12/2017 17:01:11: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15389577 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0074s; samplesPerSecond = 173068.9
12/12/2017 17:01:11:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15102466 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0081s; samplesPerSecond = 158931.2
12/12/2017 17:01:11:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15534606 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0071s; samplesPerSecond = 180086.4
12/12/2017 17:01:11:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16748519 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0072s; samplesPerSecond = 176854.2
12/12/2017 17:01:11:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15846505 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0071s; samplesPerSecond = 180660.8
12/12/2017 17:01:11:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15586510 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0075s; samplesPerSecond = 170659.8
12/12/2017 17:01:11:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16819935 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0069s; samplesPerSecond = 184728.2
12/12/2017 17:01:11: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.15685684 * 10000; EvalClassificationError = 0.07370000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.0592787s
12/12/2017 17:01:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.20'

12/12/2017 17:01:11: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:11: Starting minibatch loop.
12/12/2017 17:01:11:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16044332 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0073s; samplesPerSecond = 175164.9
12/12/2017 17:01:11:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15007914 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0072s; samplesPerSecond = 177849.4
12/12/2017 17:01:11:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15607767 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0074s; samplesPerSecond = 174000.5
12/12/2017 17:01:11:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14384937 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0075s; samplesPerSecond = 171588.7
12/12/2017 17:01:11:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16455412 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0081s; samplesPerSecond = 157948.6
12/12/2017 17:01:11:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16868048 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0081s; samplesPerSecond = 157689.8
12/12/2017 17:01:12:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16089706 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0079s; samplesPerSecond = 161875.7
12/12/2017 17:01:12: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.15813550 * 10000; EvalClassificationError = 0.07680000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.0619164s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.21'

12/12/2017 17:01:12: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15188599 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0082s; samplesPerSecond = 156882.0
12/12/2017 17:01:12:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13540890 * 1280; EvalClassificationError = 0.06093750 * 1280; time = 0.0080s; samplesPerSecond = 160555.9
12/12/2017 17:01:12:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16405790 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0074s; samplesPerSecond = 172304.7
12/12/2017 17:01:12:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16412573 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0074s; samplesPerSecond = 173894.1
12/12/2017 17:01:12:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15334044 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0083s; samplesPerSecond = 153423.9
12/12/2017 17:01:12:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15161133 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0099s; samplesPerSecond = 129533.7
12/12/2017 17:01:12:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19276142 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0071s; samplesPerSecond = 180296.9
12/12/2017 17:01:12: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16042114 * 10000; EvalClassificationError = 0.07570000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.0641131s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.22'

12/12/2017 17:01:12: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16362588 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0072s; samplesPerSecond = 178539.0
12/12/2017 17:01:12:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17052667 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0075s; samplesPerSecond = 169633.0
12/12/2017 17:01:12:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16147323 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0084s; samplesPerSecond = 151905.3
12/12/2017 17:01:12:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15935950 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0072s; samplesPerSecond = 178099.3
12/12/2017 17:01:12:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15040679 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0070s; samplesPerSecond = 183689.0
12/12/2017 17:01:12:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15705538 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0088s; samplesPerSecond = 145454.5
12/12/2017 17:01:12:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14803972 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0073s; samplesPerSecond = 175947.4
12/12/2017 17:01:12: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.15887448 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.0609795s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.23'

12/12/2017 17:01:12: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17891939 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0072s; samplesPerSecond = 178449.4
12/12/2017 17:01:12:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18593376 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0082s; samplesPerSecond = 155194.8
12/12/2017 17:01:12:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15016131 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0072s; samplesPerSecond = 177856.8
12/12/2017 17:01:12:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13410330 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0089s; samplesPerSecond = 144574.0
12/12/2017 17:01:12:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18014793 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0070s; samplesPerSecond = 181751.1
12/12/2017 17:01:12:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13521624 * 1280; EvalClassificationError = 0.05468750 * 1280; time = 0.0091s; samplesPerSecond = 141316.2
12/12/2017 17:01:12:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16167994 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0076s; samplesPerSecond = 167961.4
12/12/2017 17:01:12: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16157919 * 10000; EvalClassificationError = 0.07480000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.0653383s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.24'

12/12/2017 17:01:12: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14394474 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0114s; samplesPerSecond = 112292.5
12/12/2017 17:01:12:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17737865 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0073s; samplesPerSecond = 175129.0
12/12/2017 17:01:12:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14675841 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0077s; samplesPerSecond = 165605.8
12/12/2017 17:01:12:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15966940 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0073s; samplesPerSecond = 174834.7
12/12/2017 17:01:12:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16962881 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0073s; samplesPerSecond = 174541.5
12/12/2017 17:01:12:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17309194 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0073s; samplesPerSecond = 174337.0
12/12/2017 17:01:12:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17608681 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0079s; samplesPerSecond = 162787.7
12/12/2017 17:01:12: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16261581 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.0638256s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.25'

12/12/2017 17:01:12: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14521151 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0078s; samplesPerSecond = 163877.8
12/12/2017 17:01:12:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17816324 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0073s; samplesPerSecond = 174925.5
12/12/2017 17:01:12:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16222796 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0075s; samplesPerSecond = 170332.8
12/12/2017 17:01:12:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14471750 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0085s; samplesPerSecond = 150559.9
12/12/2017 17:01:12:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16901383 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0075s; samplesPerSecond = 170428.1
12/12/2017 17:01:12:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12451982 * 1280; EvalClassificationError = 0.05156250 * 1280; time = 0.0070s; samplesPerSecond = 183512.5
12/12/2017 17:01:12:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16381979 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0074s; samplesPerSecond = 172411.5
12/12/2017 17:01:12: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15583661 * 10000; EvalClassificationError = 0.07440000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.0606951s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.26'

12/12/2017 17:01:12: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16974514 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0077s; samplesPerSecond = 165485.9
12/12/2017 17:01:12:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16733999 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0074s; samplesPerSecond = 172662.6
12/12/2017 17:01:12:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14435418 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0086s; samplesPerSecond = 148256.3
12/12/2017 17:01:12:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14967256 * 1280; EvalClassificationError = 0.06093750 * 1280; time = 0.0093s; samplesPerSecond = 137496.9
12/12/2017 17:01:12:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15140123 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0078s; samplesPerSecond = 164184.7
12/12/2017 17:01:12:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15337338 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0073s; samplesPerSecond = 175942.6
12/12/2017 17:01:12:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16948433 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0084s; samplesPerSecond = 152270.4
12/12/2017 17:01:12: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.15804421 * 10000; EvalClassificationError = 0.07300000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.0640767s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.27'

12/12/2017 17:01:12: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16823528 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0092s; samplesPerSecond = 138839.2
12/12/2017 17:01:12:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18711107 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0073s; samplesPerSecond = 176466.5
12/12/2017 17:01:12:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16808963 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0076s; samplesPerSecond = 169350.3
12/12/2017 17:01:12:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14899745 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0071s; samplesPerSecond = 179608.8
12/12/2017 17:01:12:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13890100 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0073s; samplesPerSecond = 174303.8
12/12/2017 17:01:12:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15160427 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0073s; samplesPerSecond = 176274.5
12/12/2017 17:01:12:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16486320 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0074s; samplesPerSecond = 172103.2
12/12/2017 17:01:12: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.16216440 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.0607438s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.28'

12/12/2017 17:01:12: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15835025 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0085s; samplesPerSecond = 151327.1
12/12/2017 17:01:12:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12738969 * 1280; EvalClassificationError = 0.05781250 * 1280; time = 0.0086s; samplesPerSecond = 148654.0
12/12/2017 17:01:12:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16783977 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0073s; samplesPerSecond = 174206.5
12/12/2017 17:01:12:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14756360 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0074s; samplesPerSecond = 172606.8
12/12/2017 17:01:12:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16397972 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0075s; samplesPerSecond = 169970.9
12/12/2017 17:01:12:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14491763 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0071s; samplesPerSecond = 179828.3
12/12/2017 17:01:12:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17005711 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0075s; samplesPerSecond = 169914.5
12/12/2017 17:01:12: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.15876652 * 10000; EvalClassificationError = 0.07520000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.0615222s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.29'

12/12/2017 17:01:12: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16122833 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0075s; samplesPerSecond = 171551.9
12/12/2017 17:01:12:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15242952 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0093s; samplesPerSecond = 138149.9
12/12/2017 17:01:12:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16156282 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0093s; samplesPerSecond = 137008.3
12/12/2017 17:01:12:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18074293 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0073s; samplesPerSecond = 175969.2
12/12/2017 17:01:12:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17172909 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0074s; samplesPerSecond = 172609.1
12/12/2017 17:01:12:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16896334 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0074s; samplesPerSecond = 172655.7
12/12/2017 17:01:12:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17258568 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0077s; samplesPerSecond = 165400.3
12/12/2017 17:01:12: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.16581167 * 10000; EvalClassificationError = 0.07720000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.0632881s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.30'

12/12/2017 17:01:12: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16897355 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0083s; samplesPerSecond = 153770.4
12/12/2017 17:01:12:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16999098 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0070s; samplesPerSecond = 182565.0
12/12/2017 17:01:12:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18994935 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0074s; samplesPerSecond = 171978.3
12/12/2017 17:01:12:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14698930 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0071s; samplesPerSecond = 179131.2
12/12/2017 17:01:12:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17408614 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0074s; samplesPerSecond = 173085.2
12/12/2017 17:01:12:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14637918 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0070s; samplesPerSecond = 182559.8
12/12/2017 17:01:12:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15711241 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0075s; samplesPerSecond = 170040.9
12/12/2017 17:01:12: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.16452843 * 10000; EvalClassificationError = 0.07810000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.0592615s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.31'

12/12/2017 17:01:12: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16301147 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0101s; samplesPerSecond = 126371.1
12/12/2017 17:01:12:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14686788 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0072s; samplesPerSecond = 176974.0
12/12/2017 17:01:12:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13885822 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0073s; samplesPerSecond = 175193.7
12/12/2017 17:01:12:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15732169 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0074s; samplesPerSecond = 173618.2
12/12/2017 17:01:12:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14985080 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0076s; samplesPerSecond = 168385.6
12/12/2017 17:01:12:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16477857 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0069s; samplesPerSecond = 184987.1
12/12/2017 17:01:12:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15139675 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0074s; samplesPerSecond = 171945.9
12/12/2017 17:01:12: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15504619 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.0614371s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.32'

12/12/2017 17:01:12: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16162583 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0102s; samplesPerSecond = 126031.4
12/12/2017 17:01:12:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17066745 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0073s; samplesPerSecond = 174875.3
12/12/2017 17:01:12:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15118833 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0076s; samplesPerSecond = 167653.4
12/12/2017 17:01:12:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15539260 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0073s; samplesPerSecond = 176490.9
12/12/2017 17:01:12:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14059906 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0074s; samplesPerSecond = 171844.4
12/12/2017 17:01:12:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14768186 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0070s; samplesPerSecond = 181810.4
12/12/2017 17:01:12:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16787434 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0075s; samplesPerSecond = 171683.0
12/12/2017 17:01:12: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15615233 * 10000; EvalClassificationError = 0.07420000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.0618195s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.33'

12/12/2017 17:01:12: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13651509 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0094s; samplesPerSecond = 135583.2
12/12/2017 17:01:12:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15933895 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0071s; samplesPerSecond = 180487.6
12/12/2017 17:01:12:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16713090 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0082s; samplesPerSecond = 156573.0
12/12/2017 17:01:12:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14403644 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0069s; samplesPerSecond = 186219.7
12/12/2017 17:01:12:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16177678 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0070s; samplesPerSecond = 181882.8
12/12/2017 17:01:12:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16950922 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0073s; samplesPerSecond = 176417.9
12/12/2017 17:01:12:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16325722 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0074s; samplesPerSecond = 173038.4
12/12/2017 17:01:12: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15603025 * 10000; EvalClassificationError = 0.07570000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.0607117s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.34'

12/12/2017 17:01:12: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16672176 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0073s; samplesPerSecond = 176332.8
12/12/2017 17:01:12:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14191216 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0072s; samplesPerSecond = 176632.1
12/12/2017 17:01:12:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15464108 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0108s; samplesPerSecond = 118071.4
12/12/2017 17:01:12:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15669584 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0073s; samplesPerSecond = 175882.2
12/12/2017 17:01:12:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14840460 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0075s; samplesPerSecond = 170630.3
12/12/2017 17:01:12:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14536929 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0071s; samplesPerSecond = 181013.4
12/12/2017 17:01:12:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15993824 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0073s; samplesPerSecond = 174653.4
12/12/2017 17:01:12: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15363633 * 10000; EvalClassificationError = 0.07430000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.0616432s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.35'

12/12/2017 17:01:12: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14913505 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0086s; samplesPerSecond = 147985.4
12/12/2017 17:01:12:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18486208 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0072s; samplesPerSecond = 178357.4
12/12/2017 17:01:12:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14803789 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0101s; samplesPerSecond = 126469.7
12/12/2017 17:01:12:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15396109 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0074s; samplesPerSecond = 173842.2
12/12/2017 17:01:12:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14668994 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0071s; samplesPerSecond = 179586.1
12/12/2017 17:01:12:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13682308 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0069s; samplesPerSecond = 185415.9
12/12/2017 17:01:12:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14860573 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0075s; samplesPerSecond = 170444.0
12/12/2017 17:01:12: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15330466 * 10000; EvalClassificationError = 0.07300000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.0624436s
12/12/2017 17:01:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.36'

12/12/2017 17:01:12: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:12: Starting minibatch loop.
12/12/2017 17:01:12:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16894678 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0075s; samplesPerSecond = 170036.4
12/12/2017 17:01:12:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14590899 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0070s; samplesPerSecond = 184016.4
12/12/2017 17:01:12:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14945130 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0084s; samplesPerSecond = 152949.0
12/12/2017 17:01:12:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12509599 * 1280; EvalClassificationError = 0.05546875 * 1280; time = 0.0102s; samplesPerSecond = 126042.6
12/12/2017 17:01:12:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16078506 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0072s; samplesPerSecond = 176817.6
12/12/2017 17:01:13:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14524522 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0071s; samplesPerSecond = 180724.6
12/12/2017 17:01:13:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15973988 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0075s; samplesPerSecond = 170219.6
12/12/2017 17:01:13: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15063989 * 10000; EvalClassificationError = 0.07130000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.0625092s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.37'

12/12/2017 17:01:13: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16746482 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0080s; samplesPerSecond = 160162.2
12/12/2017 17:01:13:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14641248 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0071s; samplesPerSecond = 179121.2
12/12/2017 17:01:13:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14680152 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0079s; samplesPerSecond = 162976.4
12/12/2017 17:01:13:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15910540 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0071s; samplesPerSecond = 179492.9
12/12/2017 17:01:13:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13705158 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0073s; samplesPerSecond = 175033.2
12/12/2017 17:01:13:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15457368 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0073s; samplesPerSecond = 174863.4
12/12/2017 17:01:13:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13793364 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0075s; samplesPerSecond = 171265.0
12/12/2017 17:01:13: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15023055 * 10000; EvalClassificationError = 0.07270000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.0596664s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.38'

12/12/2017 17:01:13: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14781287 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0075s; samplesPerSecond = 170771.4
12/12/2017 17:01:13:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13780324 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0070s; samplesPerSecond = 182677.1
12/12/2017 17:01:13:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15107169 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0075s; samplesPerSecond = 171281.0
12/12/2017 17:01:13:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15137215 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0083s; samplesPerSecond = 154179.7
12/12/2017 17:01:13:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15106077 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0097s; samplesPerSecond = 132496.9
12/12/2017 17:01:13:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16847758 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0071s; samplesPerSecond = 180304.5
12/12/2017 17:01:13:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17596807 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0072s; samplesPerSecond = 178753.5
12/12/2017 17:01:13: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.15368611 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.0616609s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.39'

12/12/2017 17:01:13: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18559949 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0100s; samplesPerSecond = 127454.5
12/12/2017 17:01:13:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14538515 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0073s; samplesPerSecond = 175908.7
12/12/2017 17:01:13:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15225110 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0075s; samplesPerSecond = 170215.0
12/12/2017 17:01:13:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14976568 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0073s; samplesPerSecond = 175730.0
12/12/2017 17:01:13:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15456004 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0080s; samplesPerSecond = 160523.7
12/12/2017 17:01:13:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15915160 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0085s; samplesPerSecond = 150524.5
12/12/2017 17:01:13:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14317894 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0076s; samplesPerSecond = 168663.0
12/12/2017 17:01:13: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15353755 * 10000; EvalClassificationError = 0.07380000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.0637867s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.40'

12/12/2017 17:01:13: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16386365 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0075s; samplesPerSecond = 170605.2
12/12/2017 17:01:13:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13388780 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0072s; samplesPerSecond = 179011.0
12/12/2017 17:01:13:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14691432 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0077s; samplesPerSecond = 167176.0
12/12/2017 17:01:13:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15102983 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0073s; samplesPerSecond = 175265.6
12/12/2017 17:01:13:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14908104 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0074s; samplesPerSecond = 173143.8
12/12/2017 17:01:13:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14839249 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0070s; samplesPerSecond = 182807.5
12/12/2017 17:01:13:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15130272 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0074s; samplesPerSecond = 172135.6
12/12/2017 17:01:13: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.14857397 * 10000; EvalClassificationError = 0.07150000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.0593126s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.41'

12/12/2017 17:01:13: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14376659 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0080s; samplesPerSecond = 160590.2
12/12/2017 17:01:13:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14518926 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0076s; samplesPerSecond = 167458.2
12/12/2017 17:01:13:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15640337 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0072s; samplesPerSecond = 178357.4
12/12/2017 17:01:13:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15552282 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0070s; samplesPerSecond = 183189.5
12/12/2017 17:01:13:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15926390 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0070s; samplesPerSecond = 183210.5
12/12/2017 17:01:13:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16413403 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0070s; samplesPerSecond = 183470.5
12/12/2017 17:01:13:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17426605 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0070s; samplesPerSecond = 183158.0
12/12/2017 17:01:13: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15598906 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.0586686s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.42'

12/12/2017 17:01:13: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15915523 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0091s; samplesPerSecond = 140647.0
12/12/2017 17:01:13:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12504478 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0093s; samplesPerSecond = 137460.0
12/12/2017 17:01:13:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14653211 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0073s; samplesPerSecond = 175597.4
12/12/2017 17:01:13:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15579805 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0074s; samplesPerSecond = 173828.0
12/12/2017 17:01:13:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16196146 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0074s; samplesPerSecond = 172504.4
12/12/2017 17:01:13:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13869281 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0077s; samplesPerSecond = 166141.0
12/12/2017 17:01:13:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16450014 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0076s; samplesPerSecond = 167613.9
12/12/2017 17:01:13: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.14961868 * 10000; EvalClassificationError = 0.07480000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.0646728s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.43'

12/12/2017 17:01:13: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16129680 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0073s; samplesPerSecond = 174705.9
12/12/2017 17:01:13:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15699968 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0099s; samplesPerSecond = 129557.3
12/12/2017 17:01:13:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.12957540 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0076s; samplesPerSecond = 169133.2
12/12/2017 17:01:13:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15337853 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0076s; samplesPerSecond = 167392.5
12/12/2017 17:01:13:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15539331 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0075s; samplesPerSecond = 169653.3
12/12/2017 17:01:13:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13564801 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0075s; samplesPerSecond = 170187.9
12/12/2017 17:01:13:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16038380 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0076s; samplesPerSecond = 168787.5
12/12/2017 17:01:13: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.15072805 * 10000; EvalClassificationError = 0.07290000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.0627789s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.44'

12/12/2017 17:01:13: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15498800 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0119s; samplesPerSecond = 107126.4
12/12/2017 17:01:13:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13802500 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0073s; samplesPerSecond = 175090.6
12/12/2017 17:01:13:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15443511 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0079s; samplesPerSecond = 162961.8
12/12/2017 17:01:13:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15640473 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0077s; samplesPerSecond = 167263.4
12/12/2017 17:01:13:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14921513 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0075s; samplesPerSecond = 169545.4
12/12/2017 17:01:13:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13979254 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0080s; samplesPerSecond = 161004.3
12/12/2017 17:01:13:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15376186 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0077s; samplesPerSecond = 166538.7
12/12/2017 17:01:13: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.14844531 * 10000; EvalClassificationError = 0.07350000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.0661105s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.45'

12/12/2017 17:01:13: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.12914536 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0078s; samplesPerSecond = 163657.8
12/12/2017 17:01:13:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16663990 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0073s; samplesPerSecond = 175648.0
12/12/2017 17:01:13:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15111325 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0069s; samplesPerSecond = 185606.8
12/12/2017 17:01:13:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14401245 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0073s; samplesPerSecond = 175848.3
12/12/2017 17:01:13:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15081315 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0076s; samplesPerSecond = 168248.4
12/12/2017 17:01:13:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15450487 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0068s; samplesPerSecond = 187194.7
12/12/2017 17:01:13:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14936581 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0074s; samplesPerSecond = 173146.1
12/12/2017 17:01:13: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.14963223 * 10000; EvalClassificationError = 0.07190000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.0596016s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.46'

12/12/2017 17:01:13: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15209641 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0075s; samplesPerSecond = 171526.6
12/12/2017 17:01:13:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15732021 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0078s; samplesPerSecond = 164736.2
12/12/2017 17:01:13:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16360922 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0105s; samplesPerSecond = 122247.1
12/12/2017 17:01:13:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.11951718 * 1280; EvalClassificationError = 0.05781250 * 1280; time = 0.0070s; samplesPerSecond = 182541.6
12/12/2017 17:01:13:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13802314 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0072s; samplesPerSecond = 177531.2
12/12/2017 17:01:13:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15337863 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0094s; samplesPerSecond = 136305.1
12/12/2017 17:01:13:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14004908 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0074s; samplesPerSecond = 173047.8
12/12/2017 17:01:13: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.14584731 * 10000; EvalClassificationError = 0.07130000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.0640266s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.47'

12/12/2017 17:01:13: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15177737 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0092s; samplesPerSecond = 138565.6
12/12/2017 17:01:13:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15497197 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0073s; samplesPerSecond = 174589.1
12/12/2017 17:01:13:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15238934 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0074s; samplesPerSecond = 172966.0
12/12/2017 17:01:13:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14401417 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0072s; samplesPerSecond = 177472.1
12/12/2017 17:01:13:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14763904 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0076s; samplesPerSecond = 169108.6
12/12/2017 17:01:13:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14290252 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0069s; samplesPerSecond = 186295.6
12/12/2017 17:01:13:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13556538 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0073s; samplesPerSecond = 175792.8
12/12/2017 17:01:13: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.14651786 * 10000; EvalClassificationError = 0.07240000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.0602888s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.48'

12/12/2017 17:01:13: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16257637 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0073s; samplesPerSecond = 176182.3
12/12/2017 17:01:13:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13693624 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0068s; samplesPerSecond = 187194.7
12/12/2017 17:01:13:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15928223 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0072s; samplesPerSecond = 177494.3
12/12/2017 17:01:13:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15061374 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0069s; samplesPerSecond = 186162.9
12/12/2017 17:01:13:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14774194 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0069s; samplesPerSecond = 186752.3
12/12/2017 17:01:13:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14288821 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0073s; samplesPerSecond = 176534.7
12/12/2017 17:01:13:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18438711 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0074s; samplesPerSecond = 172846.8
12/12/2017 17:01:13: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.15321802 * 10000; EvalClassificationError = 0.07010000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.0572306s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.49'

12/12/2017 17:01:13: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14232250 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0073s; samplesPerSecond = 175940.2
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13767110 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0088s; samplesPerSecond = 145406.6
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14364045 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0092s; samplesPerSecond = 138600.1
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15275350 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0072s; samplesPerSecond = 177359.0
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13829799 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0072s; samplesPerSecond = 178158.8
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15360394 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0072s; samplesPerSecond = 178414.6
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15102825 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0072s; samplesPerSecond = 177740.7
12/12/2017 17:01:13: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14561012 * 10000; EvalClassificationError = 0.07280000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.0620086s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn'

12/12/2017 17:01:13: Action "train" complete.


12/12/2017 17:01:13: ##############################################################################
12/12/2017 17:01:13: #                                                                            #
12/12/2017 17:01:13: # Simple_Demo_Output command (write action)                                  #
12/12/2017 17:01:13: #                                                                            #
12/12/2017 17:01:13: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 12 are shared as 3, and 13 are not shared.

Here are the ones that share memory:
	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *1] }
	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1]
	  W1*H1+B1 : [50 x 1 x *1]
	  W2*H1 : [2 x 1 x *1] }
	{ H2 : [50 x 1 x *1]
	  HLast : [2 x 1 x *1]
	  MVNormalizedFeatures : [2 x *1]
	  W0*features+B0 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] }

Here are the ones that don't share memory:
	{B0 : [50 x 1]}
	{B1 : [50 x 1]}
	{B2 : [2 x 1]}
	{features : [2 x *1]}
	{InvStdOfFeatures : [2]}
	{labels : [2 x *1]}
	{MeanOfFeatures : [2]}
	{Prior : [2]}
	{W0 : [50 x 2]}
	{W1 : [50 x 50]}
	{W2 : [2 x 50]}
	{ScaledLogLikelihood : [2 x 1 x *1]}
	{LogOfPrior : [2]}

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

12/12/2017 17:01:13: Action "write" complete.

12/12/2017 17:01:13: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu DeviceId=-1 timestamping=true forceDeterministicAlgorithms=true makeMode=true
CNTK 2.3.1+ (HEAD f4f0f8, Dec 11 2017 18:34:12) at 2017/12/12 17:01:13

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  forceDeterministicAlgorithms=true  makeMode=true
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
12/12/2017 17:01:13: -------------------------------------------------------------------
12/12/2017 17:01:13: Build info: 

12/12/2017 17:01:13: 		Built time: Dec 11 2017 18:28:39
12/12/2017 17:01:13: 		Last modified date: Wed Nov 15 09:27:10 2017
12/12/2017 17:01:13: 		Build type: release
12/12/2017 17:01:13: 		Build target: GPU
12/12/2017 17:01:13: 		With 1bit-SGD: yes
12/12/2017 17:01:13: 		With ASGD: yes
12/12/2017 17:01:13: 		Math lib: mkl
12/12/2017 17:01:13: 		CUDA version: 9.0.0
12/12/2017 17:01:13: 		CUDNN version: 7.0.4
12/12/2017 17:01:13: 		Build Branch: HEAD
12/12/2017 17:01:13: 		Build SHA1: f4f0f82eabcc482dbd03af1f946a44ae2b8b97bf
12/12/2017 17:01:13: 		MPI distribution: Open MPI
12/12/2017 17:01:13: 		MPI version: 1.10.7
12/12/2017 17:01:13: -------------------------------------------------------------------
12/12/2017 17:01:13: -------------------------------------------------------------------
12/12/2017 17:01:13: GPU info:

12/12/2017 17:01:13: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/12/2017 17:01:13: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:forceDeterministicAlgorithms=true
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
12/12/2017 17:01:13: Commands: Simple_Demo Simple_Demo_Output
12/12/2017 17:01:13: precision = "float"
12/12/2017 17:01:13: WARNING: forceDeterministicAlgorithms flag is specified. Using 1 CPU thread for processing.

12/12/2017 17:01:13: ##############################################################################
12/12/2017 17:01:13: #                                                                            #
12/12/2017 17:01:13: # Simple_Demo command (train action)                                         #
12/12/2017 17:01:13: #                                                                            #
12/12/2017 17:01:13: ##############################################################################

12/12/2017 17:01:13: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn.49'.
SimpleNetworkBuilder Using CPU
12/12/2017 17:01:13: 
Model has 25 nodes. Using CPU.

12/12/2017 17:01:13: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
12/12/2017 17:01:13: Evaluation criterion: EvalClassificationError = ClassificationError

12/12/2017 17:01:13: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

12/12/2017 17:01:13: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
12/12/2017 17:01:13: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
12/12/2017 17:01:13: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
12/12/2017 17:01:13: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
12/12/2017 17:01:13: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
12/12/2017 17:01:13: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

12/12/2017 17:01:13: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/12/2017 17:01:13: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

12/12/2017 17:01:13: Starting minibatch loop.
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.14232250 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0173s; samplesPerSecond = 73877.8
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.13767110 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0082s; samplesPerSecond = 156544.3
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.14364045 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0076s; samplesPerSecond = 169422.0
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.15275350 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0076s; samplesPerSecond = 168259.4
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.13829799 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0079s; samplesPerSecond = 161075.2
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.15360394 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0074s; samplesPerSecond = 171872.1
12/12/2017 17:01:13:  Epoch[50 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.15102825 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0119s; samplesPerSecond = 107459.2
12/12/2017 17:01:13: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14561012 * 10000; EvalClassificationError = 0.07280000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.0759437s
12/12/2017 17:01:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/models/simple.dnn'

12/12/2017 17:01:13: Action "train" complete.


12/12/2017 17:01:13: ##############################################################################
12/12/2017 17:01:13: #                                                                            #
12/12/2017 17:01:13: # Simple_Demo_Output command (write action)                                  #
12/12/2017 17:01:13: #                                                                            #
12/12/2017 17:01:13: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 12 are shared as 3, and 13 are not shared.

Here are the ones that share memory:
	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *2] }
	{ H2 : [50 x 1 x *2]
	  HLast : [2 x 1 x *2]
	  MVNormalizedFeatures : [2 x *2]
	  W0*features+B0 : [50 x 1 x *2]
	  W1*H1 : [50 x 1 x *2] }
	{ H1 : [50 x 1 x *2]
	  W0*features : [50 x *2]
	  W1*H1+B1 : [50 x 1 x *2]
	  W2*H1 : [2 x 1 x *2] }

Here are the ones that don't share memory:
	{B0 : [50 x 1]}
	{B1 : [50 x 1]}
	{B2 : [2 x 1]}
	{features : [2 x *2]}
	{InvStdOfFeatures : [2]}
	{labels : [2 x *2]}
	{MeanOfFeatures : [2]}
	{Prior : [2]}
	{W0 : [50 x 2]}
	{W1 : [50 x 50]}
	{W2 : [2 x 50]}
	{ScaledLogLikelihood : [2 x 1 x *2]}
	{LogOfPrior : [2]}

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20171211223423.932710/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

12/12/2017 17:01:14: Action "write" complete.

12/12/2017 17:01:14: __COMPLETED__