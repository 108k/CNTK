CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Preparing training and test data
=== Running training
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/fcn.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data RunDir=/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN OutputDir=/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu DeviceId=-1 timestamping=true
CNTK 2.3.1+ (HEAD f4f0f8, Dec 11 2017 18:34:12) at 2017/12/12 15:02:16

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/fcn.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  RunDir=/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN  OutputDir=/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu  DeviceId=-1  timestamping=true
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Image/Data
--------------------------------------------------------------------------
[[4410,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: fdb4dbbde386

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
ping [requestnodes (before change)]: 1 nodes pinging each other
ping [requestnodes (after change)]: 1 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 1 out of 1 MPI nodes on a single host (1 requested); we (0) are in (participating)
ping [mpihelper]: 1 nodes pinging each other
12/12/2017 15:02:16: -------------------------------------------------------------------
12/12/2017 15:02:16: Build info: 

12/12/2017 15:02:16: 		Built time: Dec 11 2017 18:28:39
12/12/2017 15:02:16: 		Last modified date: Wed Nov 15 09:27:10 2017
12/12/2017 15:02:16: 		Build type: release
12/12/2017 15:02:16: 		Build target: GPU
12/12/2017 15:02:16: 		With 1bit-SGD: yes
12/12/2017 15:02:16: 		With ASGD: yes
12/12/2017 15:02:16: 		Math lib: mkl
12/12/2017 15:02:16: 		CUDA version: 9.0.0
12/12/2017 15:02:16: 		CUDNN version: 7.0.4
12/12/2017 15:02:16: 		Build Branch: HEAD
12/12/2017 15:02:16: 		Build SHA1: f4f0f82eabcc482dbd03af1f946a44ae2b8b97bf
12/12/2017 15:02:16: 		MPI distribution: Open MPI
12/12/2017 15:02:16: 		MPI version: 1.10.7
12/12/2017 15:02:16: -------------------------------------------------------------------
12/12/2017 15:02:16: -------------------------------------------------------------------
12/12/2017 15:02:16: GPU info:

12/12/2017 15:02:16: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/12/2017 15:02:16: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: fcn.cntk:ClassCount=2
configparameters: fcn.cntk:command=TrainFCN8:ConvertFCN8ToFCN4:TrainFCN4:PrepareFCN4ForTest:TestFCN4
configparameters: fcn.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN
configparameters: fcn.cntk:ConvertFCN8ToFCN4=[
    action = "edit"
    CurModel = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN8_train"
    NewModel = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_initial"
    editPath = "/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/fcn8_to_fcn4.mel"
]

configparameters: fcn.cntk:currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data
configparameters: fcn.cntk:DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data
configparameters: fcn.cntk:deviceId=-1
configparameters: fcn.cntk:Epochs=2
configparameters: fcn.cntk:FcnDataDir=/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Data
configparameters: fcn.cntk:FeatureChannels=16
configparameters: fcn.cntk:ImageChannels=1
configparameters: fcn.cntk:LrPerSample=0.01
configparameters: fcn.cntk:MbSize=16
configparameters: fcn.cntk:ModelDir=/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models
configparameters: fcn.cntk:MomentumTimeConstant=1215
configparameters: fcn.cntk:numMBsToShowResult=1
configparameters: fcn.cntk:OutputDir=/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu
configparameters: fcn.cntk:parallelTrain=true
configparameters: fcn.cntk:precision=float
configparameters: fcn.cntk:PrepareFCN4ForTest=[
    action = "edit"
    CurModel = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_train"
    NewModel = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_test"
    editPath = "/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/prepare_for_test.mel"
    TestImageHeight = 28
    TestImageWidth = 28
    ImageChannels = 1
    ClassCount = 2
]

configparameters: fcn.cntk:RunDir=/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu
configparameters: fcn.cntk:TestDataFile=Test_cntk_fcn_text.txt
configparameters: fcn.cntk:TestFCN4=[
    action = test
    numMBsToShowResult = 20
    modelPath = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_test"
    minibatchSize = 16
distributedMBReading = "true" 
    BrainScriptNetworkBuilder = [
        m = BS.Network.Load("/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_test")
        evaluationNodes = (m.pixelwiseError:m.miouError)
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TestFeaturesDim=784
configparameters: fcn.cntk:TestIgnoreDim=784
configparameters: fcn.cntk:TestImageHeight=28
configparameters: fcn.cntk:TestImageWidth=28
configparameters: fcn.cntk:TestLabelsDim=1568
configparameters: fcn.cntk:timestamping=true
configparameters: fcn.cntk:traceLevel=1
configparameters: fcn.cntk:TrainDataFile=Train_cntk_fcn_text.txt
configparameters: fcn.cntk:TrainFCN4=[
    action = "train"
    modelPath = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_train"
    saveBestModelPerCriterion = "true"
    BrainScriptNetworkBuilder = [
        include "/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/shared.bs"
        classCount = 2
        featureChannels = 16
        inModel = BS.Network.Load("/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_initial")
        predictionFCN4 = ConvLayer1x1MSRAInit(inModel.featuresFCN4, featureChannels, classCount, 1, 1)
        upsampledFCN8 = LearnableUpsamplingLayer{classCount, classCount, 4, 2}(inModel.predictionFCN8)
        cropFCN8 = CropAutomatic(upsampledFCN8, predictionFCN4)
        fusionFCN4 = Plus(cropFCN8, predictionFCN4)
        upsampledFCN4 = BilinearUpsamplingLayer{classCount, 8, 4}(fusionFCN4)
        out = CropAutomaticGivenAncestors(upsampledFCN4, inModel.labels, inModel.features, inModel.labels)
        CE = CrossEntropyWithSoftmaxNDNormalized(inModel.labels, out, inModel.ignoreMask, axis = 3, tag = 'criterion')
        pixelwiseError = PixelError(inModel.labels, out, inModel.ignoreMask)
        miouError = MeanIOUError(inModel.labels, out, inModel.ignoreMask, classCount = classCount)
        featureNodes    = (inModel.features)
        labelNodes      = (inModel.labels)
        criterionNodes  = (CE)
        evaluationNodes = (pixelwiseError:miouError)
        outputNodes     = (out)
    ]
    SGD = [
        minibatchSize = 16
        learningRatesPerSample = 0.01
        momentumAsTimeConstant= 1215
        maxEpochs = 2
        gradUpdateType = "None"
        L2RegWeight = 0.00000390625
        dropoutRate = 0
        minLearningRatePerSample = 1e-15
disableWkInBatchNormal = "true" 
        ParallelTrain = [
            parallelizationMethod = "DataParallelSGD"
            distributedMBReading = "true"
            parallelizationStartEpoch = 1
            DataParallelSGD = [
                gradientBits = 32
            ]
        ]
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Data/Train_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
    cvReader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TrainFCN8=[
    action = "train"
    modelPath = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN8_train"
    saveBestModelPerCriterion = "true"
    BrainScriptNetworkBuilder = [
        include "/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/shared.bs"
        classCount = 2
        imageWidth = 28
        imageHeight = 28
        imageChannels = 1
        featureChannels = 16
        bnTimeConst = 15992
        features = ImageInput(imageWidth, imageHeight, imageChannels, imageLayout = "cudnn", tag = 'feature')
        labels = ImageInput(imageWidth, imageHeight, classCount, imageLayout = "cudnn", tag = 'label')
        ignoreMask = ImageInput(imageWidth, imageHeight, 1, imageLayout = "cudnn", tag = 'feature')
        featuresFCN4 = Sequential(
            ConvBNReLULayer{featureChannels, /*kernel*/ (7:7), /*stride*/ (2:2), bnTimeConst} :
            MaxPoolingLayer{(3:3), stride = 2, pad = true})(features)
        featuresFCN8 = Sequential(
            ResNetBasicInc{featureChannels, /*stride*/ (2:2), bnTimeConst} :
            ResNetBasic{featureChannels, bnTimeConst})(featuresFCN4)
        predictionFCN8 = ConvLayer1x1MSRAInit(featuresFCN8, featureChannels, classCount, 1, 1)
        upsampledFCN8 = BilinearUpsamplingLayer{classCount, 16, 8}(predictionFCN8)
        out = CropAutomaticGivenAncestors(upsampledFCN8, labels, features, labels)
        CE = CrossEntropyWithSoftmaxNDNormalized(labels, out, ignoreMask, axis = 3, tag = 'criterion')
        pixelwiseError = PixelError(labels, out, ignoreMask)
        miouError = MeanIOUError(labels, out, ignoreMask, classCount = classCount)
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (CE)
        evaluationNodes = (pixelwiseError:miouError)
        outputNodes     = (out)
    ]
    SGD = [
        minibatchSize = 16
        learningRatesPerSample = 0.01
        momentumAsTimeConstant = 1215
        maxEpochs = 2
        gradUpdateType = "None"
        L2RegWeight = 0.00000390625
        dropoutRate = 0
        minLearningRatePerSample = 1e-15
disableWkInBatchNormal = "true" 
        ParallelTrain = [
            parallelizationMethod = "DataParallelSGD"
            distributedMBReading = "true"
            parallelizationStartEpoch = 1
            DataParallelSGD = [
                gradientBits = 32
            ]
        ]
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Data/Train_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
    cvReader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TrainFeaturesDim=784
configparameters: fcn.cntk:TrainIgnoreDim=784
configparameters: fcn.cntk:TrainImageHeight=28
configparameters: fcn.cntk:TrainImageWidth=28
configparameters: fcn.cntk:TrainLabelsDim=1568
configparameters: fcn.cntk:ValDataFile=Test_cntk_fcn_text.txt
configparameters: fcn.cntk:WeightDecay=0.00000390625
12/12/2017 15:02:16: Commands: TrainFCN8 ConvertFCN8ToFCN4 TrainFCN4 PrepareFCN4ForTest TestFCN4
12/12/2017 15:02:16: precision = "float"

12/12/2017 15:02:16: ##############################################################################
12/12/2017 15:02:16: #                                                                            #
12/12/2017 15:02:16: # TrainFCN8 command (train action)                                           #
12/12/2017 15:02:16: #                                                                            #
12/12/2017 15:02:16: ##############################################################################

12/12/2017 15:02:16: 
Creating virgin network.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[7 x 7 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[1 x 1 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.

Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 108 nodes to process in pass 1.

Validating --> upsampledFCN8.W = LearnableParameter() :  -> [16 x 16 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 0 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *]
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [7 x 7 x 1 x 16].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[7 x 7 x 1 x 16] <- heNormal(seed=6, init dims=[784 x 49], range=0.202031(0.202031*1.000000), onCPU=true.
)Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *] -> [7 x 7 x 16 x *]
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=5, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=4, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 0 x 16]
Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [1 x 1 x 16 x 16].
Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[1 x 1 x 16 x 16] <- heNormal(seed=7, init dims=[16 x 16], range=0.353553(0.353553*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=3, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=2, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 2 x *]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [16 x 16 x 2 x 2], [4 x 4 x 2 x *] -> [40 x 40 x 2 x *]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *]
Validating --> out = Crop (upsampledFCN8, labels, features, labels) : [40 x 40 x 2 x *], [28 x 28 x 2 x *], [28 x 28 x 1 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *] -> [784 x 2 x *]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *] -> [1 x 2 x *]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *] -> [784 x 2 x *]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *] -> [1 x 2 x *]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *] -> [1 x *]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *] -> [1 x *]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *] -> [1 x *]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *], [1 x *] -> [1 x *]

Validating network. 64 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 40 x 40 x 2, Output: 4 x 4 x 2, Kernel: 16 x 16 x 2, Map: 2, Stride: 8 x 8 x 8, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

12/12/2017 15:02:16: 
Model has 108 nodes. Using CPU.

12/12/2017 15:02:16: Training criterion:   CE = ElementTimes

12/12/2017 15:02:16: Evaluation criteria:
12/12/2017 15:02:16: 	pixelwiseError = ElementTimes
12/12/2017 15:02:16: 	miouError = Minus


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 12 are aliased.
	miouError.union (gradient) reuses miouError.unionFlat (gradient)
	miouError.union.MinusArgs[0] (gradient) reuses miouError.unionFlat (gradient)
	featuresFCN8.b (gradient) reuses featuresFCN8.p (gradient)
	featuresFCN8.x.s (gradient) reuses featuresFCN8.x.p (gradient)
	miouError.u (gradient) reuses miouError.reciprocalUnion.z (gradient)
	featuresFCN8.x.b (gradient) reuses featuresFCN8.x.p (gradient)
	CE.log_sum.r (gradient) reuses CE.diff (gradient)

Memory Sharing: Out of 159 matrices, 96 are shared as 27, and 63 are not shared.

Here are the ones that share memory:
	{ CE.out_shift : [28 x 28 x 2 x *]
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }
	{ CE.logits_per_class : [28 x 28 x 2 x *]
	  miouError.outHardmax.isMax : [28 x 28 x 2 x *] }
	{ CE.diff : [28 x 28 x 1 x *] (gradient)
	  CE.log_sum.r : [28 x 28 x 1 x *] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16] (gradient)
	  pixelwiseError.diffs : [28 x 28 x 1 x *]
	  pixelwiseError.pixelNorm.z.r : [1 x *] }
	{ featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  miouError.reciprocalUnion.z : [1 x 2] }
	{ featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *]
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *] }
	{ CE.out_shift : [28 x 28 x 2 x *] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN4.x : [14 x 14 x 16 x *] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *]
	  miouError.union : [28 x 28 x 2 x *]
	  upsampledFCN8 : [40 x 40 x 2 x *] (gradient) }
	{ CE : [1] (gradient)
	  miouError.miou : [1] }
	{ CE.ce_unnorm : [1]
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *]
	  featuresFCN8.x.b : [4 x 4 x 16 x *] }
	{ CE.logits_per_class : [28 x 28 x 2 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  miouError.intersection : [28 x 28 x 2 x *]
	  out : [28 x 28 x 2 x *] (gradient)
	  pixelwiseError.acc._ : [28 x 28 x 2 x *] }
	{ CE.out_max.r : [28 x 28 x 1 x *]
	  featuresFCN8 : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.p : [4 x 4 x 16 x *]
	  featuresFCN8.x.b : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s : [4 x 4 x 16 x *] (gradient) }
	{ CE.norm_factor.z : [1]
	  miouError.i : [1 x 2] }
	{ CE.ce_unnorm : [1] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  miouError.iou : [1 x 2]
	  miouError.u : [1 x 2] }
	{ featuresFCN4.x : [14 x 14 x 16 x *]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *] (gradient) }
	{ featuresFCN4 : [7 x 7 x 16 x *] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  out : [28 x 28 x 2 x *] }
	{ featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *] }
	{ featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *]
	  featuresFCN8.x.s : [4 x 4 x 16 x *] }
	{ CE.log_sum.r : [28 x 28 x 1 x *]
	  featuresFCN8.b : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.p : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *] (gradient) }
	{ CE.diff : [28 x 28 x 1 x *]
	  featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }
	{ CE.diff_valid : [28 x 28 x 1 x *]
	  CE.diff_valid : [28 x 28 x 1 x *] (gradient)
	  CE.logits.r : [28 x 28 x 1 x *] (gradient)
	  CE.out_max.r : [28 x 28 x 1 x *] (gradient)
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  pixelwiseError.acc.r : [28 x 28 x 1 x *] }
	{ featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *] (gradient)
	  upsampledFCN8 : [40 x 40 x 2 x *] }
	{ CE.logits.r : [28 x 28 x 1 x *]
	  miouError.labelMasked : [28 x 28 x 2 x *] }
	{ featuresFCN8 : [4 x 4 x 16 x *]
	  featuresFCN8.b : [4 x 4 x 16 x *]
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *] (gradient) }
	{ featuresFCN8.b.x : [4 x 4 x 16 x *]
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *]
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *] (gradient) }
	{ miouError.intersectionByClass.r : [1 x 2 x *]
	  miouError.unionByClass.r : [1 x 2 x *]
	  pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *] }
	{ miouError.intersectionFlat : [784 x 2 x *]
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *]
	  miouError.unionFlat : [784 x 2 x *]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *] }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *] }

Here are the ones that don't share memory:
	{ignoreMask : [28 x 28 x 1 x *]}
	{pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *]}
	{upsampledFCN8.W : [16 x 16 x 2 x 2]}
	{CE : [1]}
	{miouError.norm : [1]}
	{predictionFCN8.W : [2 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)}
	{miouError.norm.z : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN4.x._.x.c : [14 x 14 x 16 x *]}
	{featuresFCN8.x.b.x : [4 x 4 x 16 x *]}
	{predictionFCN8.W : [2 x 16] (gradient)}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN4 : [7 x 7 x 16 x *]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{pixelwiseError.errSum.r : [1 x *]}
	{BS.Constants.One : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{miouError : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{labels : [28 x 28 x 2 x *]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *]}
	{miouError.iouSum.r : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.x.c : [4 x 4 x 16 x *]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{miouError.reciprocalUnion : [1 x 2]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{pixelwiseError : [1 x *]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{pixelwiseError.pixelNorm : [1 x *]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{miouError.outMasked : [28 x 28 x 2 x *]}
	{CE.norm_factor : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *]}
	{features : [28 x 28 x 1 x *]}


12/12/2017 15:02:16: Training 10480 parameters in 19 out of 19 parameter tensors and 51 nodes with gradient:

12/12/2017 15:02:16: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [7 x 7 x 1 x 16]
12/12/2017 15:02:16: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/12/2017 15:02:16: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/12/2017 15:02:16: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/12/2017 15:02:16: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/12/2017 15:02:16: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) : [1 x 1 x 16 x 16]
12/12/2017 15:02:16: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:16: 	Node 'predictionFCN8.W' (LearnableParameter operation) : [2 x 16]

Initializing dataParallelSGD with FP32 aggregation.
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:16: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/12/2017 15:02:16: Starting Epoch 1: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

12/12/2017 15:02:16: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
12/12/2017 15:02:17:  Epoch[ 1 of 2]-Minibatch[   1-   1]: CE = 0.05358127 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67398942 * 1; time = 0.7513s; samplesPerSecond = 21.3
12/12/2017 15:02:17:  Epoch[ 1 of 2]-Minibatch[   2-   2]: CE = 0.05348113 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67441511 * 1; time = 0.0308s; samplesPerSecond = 519.7
12/12/2017 15:02:17:  Epoch[ 1 of 2]-Minibatch[   3-   3]: CE = 0.05336735 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67430866 * 1; time = 0.0268s; samplesPerSecond = 598.1
12/12/2017 15:02:17:  Epoch[ 1 of 2]-Minibatch[   4-   4]: CE = 0.05368706 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67455792 * 1; time = 0.0303s; samplesPerSecond = 527.8
12/12/2017 15:02:17:  Epoch[ 1 of 2]-Minibatch[   5-   5]: CE = 0.05335813 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67504084 * 1; time = 0.0274s; samplesPerSecond = 584.4
12/12/2017 15:02:17:  Epoch[ 1 of 2]-Minibatch[   6-   6]: CE = 0.05369278 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67514026 * 1; time = 0.0310s; samplesPerSecond = 515.6
12/12/2017 15:02:17:  Epoch[ 1 of 2]-Minibatch[   7-   7]: CE = 0.05265896 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67507046 * 1; time = 0.0271s; samplesPerSecond = 589.4
12/12/2017 15:02:17:  Epoch[ 1 of 2]-Minibatch[   8-   8]: CE = 0.05230935 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.67532289 * 1; time = 0.0272s; samplesPerSecond = 588.5
12/12/2017 15:02:17:  Epoch[ 1 of 2]-Minibatch[   9-   9]: CE = 0.05198928 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67511535 * 1; time = 0.0289s; samplesPerSecond = 553.1
12/12/2017 15:02:17:  Epoch[ 1 of 2]-Minibatch[  10-  10]: CE = 0.05222529 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67508686 * 1; time = 0.0277s; samplesPerSecond = 576.7
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  11-  11]: CE = 0.05389462 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67506289 * 1; time = 0.0275s; samplesPerSecond = 582.8
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  12-  12]: CE = 0.05333264 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67526424 * 1; time = 0.0286s; samplesPerSecond = 559.9
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  13-  13]: CE = 0.05272815 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.67540675 * 1; time = 0.0281s; samplesPerSecond = 569.7
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  14-  14]: CE = 0.05209519 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67514789 * 1; time = 0.0266s; samplesPerSecond = 601.1
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  15-  15]: CE = 0.05225393 * 16; pixelwiseError = 0.50127548 * 16; miouError = 0.67502189 * 1; time = 0.0283s; samplesPerSecond = 564.7
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  16-  16]: CE = 0.05167080 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.67490751 * 1; time = 0.0276s; samplesPerSecond = 579.4
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  17-  17]: CE = 0.05176314 * 16; pixelwiseError = 0.49896365 * 16; miouError = 0.67495859 * 1; time = 0.0282s; samplesPerSecond = 567.4
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  18-  18]: CE = 0.05266291 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67491794 * 1; time = 0.0281s; samplesPerSecond = 569.8
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  19-  19]: CE = 0.05159565 * 16; pixelwiseError = 0.49848533 * 16; miouError = 0.67501092 * 1; time = 0.0274s; samplesPerSecond = 583.2
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  20-  20]: CE = 0.05183943 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67500407 * 1; time = 0.0274s; samplesPerSecond = 584.4
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  21-  21]: CE = 0.05289965 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67495596 * 1; time = 0.0287s; samplesPerSecond = 556.9
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  22-  22]: CE = 0.05099521 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.67506927 * 1; time = 0.0282s; samplesPerSecond = 567.7
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  23-  23]: CE = 0.05251539 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67518246 * 1; time = 0.0323s; samplesPerSecond = 494.7
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  24-  24]: CE = 0.05193304 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67510211 * 1; time = 0.0368s; samplesPerSecond = 434.7
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  25-  25]: CE = 0.05142954 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67501867 * 1; time = 0.0308s; samplesPerSecond = 519.3
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  26-  26]: CE = 0.05142088 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67494607 * 1; time = 0.0283s; samplesPerSecond = 564.8
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  27-  27]: CE = 0.05044032 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67490304 * 1; time = 0.0243s; samplesPerSecond = 657.4
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  28-  28]: CE = 0.05047079 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67470390 * 1; time = 0.0160s; samplesPerSecond = 1002.2
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  29-  29]: CE = 0.05127443 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67464459 * 1; time = 0.0175s; samplesPerSecond = 914.2
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  30-  30]: CE = 0.05085520 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.67467296 * 1; time = 0.0172s; samplesPerSecond = 931.4
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  31-  31]: CE = 0.05155106 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67465842 * 1; time = 0.0332s; samplesPerSecond = 481.2
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  32-  32]: CE = 0.05023824 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.67464674 * 1; time = 0.0164s; samplesPerSecond = 977.2
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  33-  33]: CE = 0.05065095 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67471075 * 1; time = 0.0171s; samplesPerSecond = 937.6
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  34-  34]: CE = 0.05021257 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67462003 * 1; time = 0.0175s; samplesPerSecond = 913.2
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  35-  35]: CE = 0.05021331 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67457265 * 1; time = 0.0188s; samplesPerSecond = 851.5
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  36-  36]: CE = 0.04962942 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67442656 * 1; time = 0.0173s; samplesPerSecond = 923.7
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  37-  37]: CE = 0.04995875 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.67431736 * 1; time = 0.0168s; samplesPerSecond = 954.8
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  38-  38]: CE = 0.04905780 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67424864 * 1; time = 0.0182s; samplesPerSecond = 880.3
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  39-  39]: CE = 0.04903952 * 16; pixelwiseError = 0.49872449 * 16; miouError = 0.67405832 * 1; time = 0.0172s; samplesPerSecond = 932.2
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  40-  40]: CE = 0.04942052 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67393041 * 1; time = 0.0203s; samplesPerSecond = 789.3
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  41-  41]: CE = 0.04903768 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.67384583 * 1; time = 0.0218s; samplesPerSecond = 733.5
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  42-  42]: CE = 0.04925746 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67371094 * 1; time = 0.0175s; samplesPerSecond = 916.4
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  43-  43]: CE = 0.04858892 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.67352611 * 1; time = 0.0177s; samplesPerSecond = 902.4
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  44-  44]: CE = 0.04879073 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67342883 * 1; time = 0.0170s; samplesPerSecond = 941.1
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  45-  45]: CE = 0.04846422 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67336798 * 1; time = 0.0179s; samplesPerSecond = 891.8
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  46-  46]: CE = 0.04976220 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67332256 * 1; time = 0.0174s; samplesPerSecond = 918.8
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  47-  47]: CE = 0.04835910 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67324573 * 1; time = 0.0171s; samplesPerSecond = 937.0
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  48-  48]: CE = 0.04839681 * 16; pixelwiseError = 0.49912310 * 16; miouError = 0.67312366 * 1; time = 0.0178s; samplesPerSecond = 900.6
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  49-  49]: CE = 0.04807594 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67301500 * 1; time = 0.0172s; samplesPerSecond = 929.6
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  50-  50]: CE = 0.04865008 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67287570 * 1; time = 0.0183s; samplesPerSecond = 876.1
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  51-  51]: CE = 0.04807379 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67276657 * 1; time = 0.0183s; samplesPerSecond = 874.2
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  52-  52]: CE = 0.04832959 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67266512 * 1; time = 0.0184s; samplesPerSecond = 869.3
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  53-  53]: CE = 0.04854285 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.67255127 * 1; time = 0.0182s; samplesPerSecond = 879.7
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  54-  54]: CE = 0.04867933 * 16; pixelwiseError = 0.49856505 * 16; miouError = 0.67244196 * 1; time = 0.0172s; samplesPerSecond = 928.7
12/12/2017 15:02:18:  Epoch[ 1 of 2]-Minibatch[  55-  55]: CE = 0.04762814 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67233789 * 1; time = 0.0169s; samplesPerSecond = 948.2
12/12/2017 15:02:19:  Epoch[ 1 of 2]-Minibatch[  56-  56]: CE = 0.04807352 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67224944 * 1; time = 0.0168s; samplesPerSecond = 951.3
12/12/2017 15:02:19:  Epoch[ 1 of 2]-Minibatch[  57-  57]: CE = 0.04766813 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.67212570 * 1; time = 0.0256s; samplesPerSecond = 626.2
12/12/2017 15:02:19:  Epoch[ 1 of 2]-Minibatch[  58-  58]: CE = 0.04836567 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67193985 * 1; time = 0.0181s; samplesPerSecond = 884.1
12/12/2017 15:02:19:  Epoch[ 1 of 2]-Minibatch[  59-  59]: CE = 0.04791133 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.67184752 * 1; time = 0.0173s; samplesPerSecond = 927.1
12/12/2017 15:02:19:  Epoch[ 1 of 2]-Minibatch[  60-  60]: CE = 0.04734953 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67174011 * 1; time = 0.0171s; samplesPerSecond = 936.9
12/12/2017 15:02:19:  Epoch[ 1 of 2]-Minibatch[  61-  61]: CE = 0.04762775 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67164302 * 1; time = 0.0182s; samplesPerSecond = 881.1
12/12/2017 15:02:19:  Epoch[ 1 of 2]-Minibatch[  62-  62]: CE = 0.04713611 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67151016 * 1; time = 0.0173s; samplesPerSecond = 924.8
12/12/2017 15:02:19:  Epoch[ 1 of 2]-Minibatch[  63-  63]: CE = 0.09483357 * 8; pixelwiseError = 0.50000000 * 8; miouError = 0.67144531 * 1; time = 0.0199s; samplesPerSecond = 402.1
12/12/2017 15:02:19:  Epoch[ 1 of 2]-Minibatch[  64-  64]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.67144531 * 1; time = 0.0003s; samplesPerSecond = 0.0
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:19: Finished Epoch[ 1 of 2]: [Training] CE = 0.05085727 * 1000; pixelwiseError = 0.49977423 * 1000; miouError = 0.67144531 * 1; totalSamplesSeen = 1000; learningRatePerSample = 0.0099999998; epochTime=2.18117s
NcclComm: disabled, at least one rank using CPU device
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:19: Final Results: Minibatch[1-8]: CE = 0.05367611 * 100; pixelwiseError = 0.50012754 * 100; miouError = 0.66783655 * 1
12/12/2017 15:02:19: Finished Epoch[ 1 of 2]: [Validate] CE = 0.05367611 * 100; pixelwiseError = 0.50012754 * 100; miouError = 0.66783655 * 1
12/12/2017 15:02:19: Best epoch per criterion so far: [Validate] CE = 0.053676 (Epoch 1); pixelwiseError = 0.500128 (Epoch 1); miouError = 0.667837 (Epoch 1)
12/12/2017 15:02:19: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN8_train.1'

12/12/2017 15:02:19: Starting Epoch 2: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

12/12/2017 15:02:19: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[   1-   1, 0.00%]: CE = 0.04700530 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.66612023 * 1; time = 0.0240s; samplesPerSecond = 665.5
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[   2-   2, 0.00%]: CE = 0.04714896 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.66607058 * 1; time = 0.0176s; samplesPerSecond = 911.6
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[   3-   3, 0.00%]: CE = 0.04765606 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.66636348 * 1; time = 0.0171s; samplesPerSecond = 935.3
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[   4-   4, 0.00%]: CE = 0.04804963 * 16; pixelwiseError = 0.50079721 * 16; miouError = 0.66675496 * 1; time = 0.0185s; samplesPerSecond = 865.0
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[   5-   5, 0.00%]: CE = 0.04675575 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66669345 * 1; time = 0.0178s; samplesPerSecond = 897.7
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[   6-   6, 0.00%]: CE = 0.04724498 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66669381 * 1; time = 0.0185s; samplesPerSecond = 864.0
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[   7-   7, 0.00%]: CE = 0.04702473 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.66650677 * 1; time = 0.0170s; samplesPerSecond = 942.1
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[   8-   8, 0.00%]: CE = 0.04676036 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66648233 * 1; time = 0.0170s; samplesPerSecond = 940.4
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[   9-   9, 0.00%]: CE = 0.04685756 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.66642594 * 1; time = 0.0172s; samplesPerSecond = 928.2
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  10-  10, 0.00%]: CE = 0.04695169 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.66650176 * 1; time = 0.0180s; samplesPerSecond = 890.5
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  11-  11, 0.00%]: CE = 0.04675255 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.66654861 * 1; time = 0.0177s; samplesPerSecond = 904.5
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  12-  12, 0.00%]: CE = 0.04688533 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66649508 * 1; time = 0.0182s; samplesPerSecond = 877.6
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  13-  13, 0.00%]: CE = 0.04710720 * 16; pixelwiseError = 0.50047827 * 16; miouError = 0.66652811 * 1; time = 0.0178s; samplesPerSecond = 897.1
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  14-  14, 0.00%]: CE = 0.04658855 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.66655135 * 1; time = 0.0177s; samplesPerSecond = 903.6
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  15-  15, 0.00%]: CE = 0.04683067 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66655540 * 1; time = 0.0169s; samplesPerSecond = 944.3
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  16-  16, 0.00%]: CE = 0.04657698 * 16; pixelwiseError = 0.49928254 * 16; miouError = 0.66651917 * 1; time = 0.0173s; samplesPerSecond = 927.0
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  17-  17, 0.00%]: CE = 0.04679941 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.66654468 * 1; time = 0.0174s; samplesPerSecond = 920.2
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  18-  18, 0.00%]: CE = 0.04660969 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66651946 * 1; time = 0.0184s; samplesPerSecond = 869.3
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  19-  19, 0.00%]: CE = 0.04645383 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.66645807 * 1; time = 0.0179s; samplesPerSecond = 893.8
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  20-  20, 0.00%]: CE = 0.04691669 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.66647089 * 1; time = 0.0173s; samplesPerSecond = 926.2
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  21-  21, 0.00%]: CE = 0.04672647 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66647673 * 1; time = 0.0174s; samplesPerSecond = 917.7
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  22-  22, 0.00%]: CE = 0.04685834 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66648823 * 1; time = 0.0181s; samplesPerSecond = 885.0
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  23-  23, 0.00%]: CE = 0.04632743 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.66651535 * 1; time = 0.0170s; samplesPerSecond = 943.9
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  24-  24, 0.00%]: CE = 0.04620087 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66651821 * 1; time = 0.2192s; samplesPerSecond = 73.0
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  25-  25, 0.00%]: CE = 0.04644266 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66654706 * 1; time = 0.0163s; samplesPerSecond = 984.4
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  26-  26, 0.00%]: CE = 0.04647170 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.66662008 * 1; time = 0.0186s; samplesPerSecond = 862.1
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  27-  27, 0.00%]: CE = 0.04656702 * 16; pixelwiseError = 0.49848533 * 16; miouError = 0.66658467 * 1; time = 0.0175s; samplesPerSecond = 913.2
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  28-  28, 0.00%]: CE = 0.04652092 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66661024 * 1; time = 0.0189s; samplesPerSecond = 848.4
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  29-  29, 0.00%]: CE = 0.04622016 * 16; pixelwiseError = 0.49808672 * 16; miouError = 0.66658390 * 1; time = 0.0183s; samplesPerSecond = 874.6
12/12/2017 15:02:19:  Epoch[ 2 of 2]-Minibatch[  30-  30, 0.00%]: CE = 0.04661599 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66662139 * 1; time = 0.0179s; samplesPerSecond = 895.2
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  31-  31, 0.00%]: CE = 0.04641054 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.66666597 * 1; time = 0.0174s; samplesPerSecond = 918.7
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  32-  32, 0.00%]: CE = 0.04644873 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66669184 * 1; time = 0.0171s; samplesPerSecond = 935.0
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  33-  33, 0.00%]: CE = 0.04617939 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.66668218 * 1; time = 0.0174s; samplesPerSecond = 919.4
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  34-  34, 0.00%]: CE = 0.04607065 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66671765 * 1; time = 0.0174s; samplesPerSecond = 919.8
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  35-  35, 0.00%]: CE = 0.04620326 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.66673195 * 1; time = 0.0178s; samplesPerSecond = 897.2
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  36-  36, 0.00%]: CE = 0.04600705 * 16; pixelwiseError = 0.49864477 * 16; miouError = 0.66672432 * 1; time = 0.0180s; samplesPerSecond = 889.5
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  37-  37, 0.00%]: CE = 0.04620465 * 16; pixelwiseError = 0.49912310 * 16; miouError = 0.66676116 * 1; time = 0.0184s; samplesPerSecond = 867.7
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  38-  38, 0.00%]: CE = 0.04619186 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.66677809 * 1; time = 0.0181s; samplesPerSecond = 883.9
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  39-  39, 0.00%]: CE = 0.04603155 * 16; pixelwiseError = 0.49776787 * 16; miouError = 0.66675603 * 1; time = 0.0177s; samplesPerSecond = 903.5
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  40-  40, 0.00%]: CE = 0.04587527 * 16; pixelwiseError = 0.49880421 * 16; miouError = 0.66677260 * 1; time = 0.0193s; samplesPerSecond = 830.5
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  41-  41, 0.00%]: CE = 0.04610759 * 16; pixelwiseError = 0.49888393 * 16; miouError = 0.66679430 * 1; time = 0.0179s; samplesPerSecond = 893.9
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  42-  42, 0.00%]: CE = 0.04596634 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.66679448 * 1; time = 0.0181s; samplesPerSecond = 882.5
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  43-  43, 0.00%]: CE = 0.04600801 * 16; pixelwiseError = 0.49896365 * 16; miouError = 0.66680694 * 1; time = 0.0183s; samplesPerSecond = 876.0
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  44-  44, 0.00%]: CE = 0.04608740 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.66679984 * 1; time = 0.0172s; samplesPerSecond = 932.5
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  45-  45, 0.00%]: CE = 0.04595245 * 16; pixelwiseError = 0.49784759 * 16; miouError = 0.66678214 * 1; time = 0.0177s; samplesPerSecond = 904.6
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  46-  46, 0.00%]: CE = 0.04611257 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.66680086 * 1; time = 0.0170s; samplesPerSecond = 941.4
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  47-  47, 0.00%]: CE = 0.04594598 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66685522 * 1; time = 0.0174s; samplesPerSecond = 919.0
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  48-  48, 0.00%]: CE = 0.04565834 * 16; pixelwiseError = 0.49864477 * 16; miouError = 0.66687727 * 1; time = 0.0179s; samplesPerSecond = 892.1
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  49-  49, 0.00%]: CE = 0.04572568 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.66690481 * 1; time = 0.0169s; samplesPerSecond = 946.6
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  50-  50, 0.00%]: CE = 0.04577855 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.66691452 * 1; time = 0.0174s; samplesPerSecond = 922.0
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  51-  51, 0.00%]: CE = 0.04588785 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66695160 * 1; time = 0.0185s; samplesPerSecond = 866.9
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  52-  52, 0.00%]: CE = 0.04579720 * 16; pixelwiseError = 0.49912310 * 16; miouError = 0.66696054 * 1; time = 0.0178s; samplesPerSecond = 899.6
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  53-  53, 0.00%]: CE = 0.04578784 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66698211 * 1; time = 0.0171s; samplesPerSecond = 936.9
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  54-  54, 0.00%]: CE = 0.04561340 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.66701579 * 1; time = 0.0181s; samplesPerSecond = 884.3
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  55-  55, 0.00%]: CE = 0.04561172 * 16; pixelwiseError = 0.49768814 * 16; miouError = 0.66701281 * 1; time = 0.0175s; samplesPerSecond = 916.3
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  56-  56, 0.00%]: CE = 0.04555626 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.66700423 * 1; time = 0.0169s; samplesPerSecond = 946.2
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  57-  57, 0.00%]: CE = 0.04548032 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.66703916 * 1; time = 0.0169s; samplesPerSecond = 947.4
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  58-  58, 0.00%]: CE = 0.04564892 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.66706038 * 1; time = 0.0174s; samplesPerSecond = 917.8
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  59-  59, 0.00%]: CE = 0.04551115 * 16; pixelwiseError = 0.49713010 * 16; miouError = 0.66704732 * 1; time = 0.0185s; samplesPerSecond = 866.8
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  60-  60, 0.00%]: CE = 0.04540698 * 16; pixelwiseError = 0.49736926 * 16; miouError = 0.66704196 * 1; time = 0.0177s; samplesPerSecond = 902.4
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  61-  61, 0.00%]: CE = 0.04547752 * 16; pixelwiseError = 0.49808672 * 16; miouError = 0.66702902 * 1; time = 0.0177s; samplesPerSecond = 904.9
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  62-  62, 0.00%]: CE = 0.04542794 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.66706228 * 1; time = 0.0182s; samplesPerSecond = 878.4
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  63-  63, 0.00%]: CE = 0.09121783 * 8; pixelwiseError = 0.49936223 * 8; miouError = 0.66707611 * 1; time = 0.0184s; samplesPerSecond = 435.7
12/12/2017 15:02:20:  Epoch[ 2 of 2]-Minibatch[  64-  64, 0.00%]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.66707611 * 1; time = 0.0003s; samplesPerSecond = 0.0
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:20: Finished Epoch[ 2 of 2]: [Training] CE = 0.04668335 * 1000; pixelwiseError = 0.49927933 * 1000; miouError = 0.66707611 * 1; totalSamplesSeen = 2000; learningRatePerSample = 0.0099999998; epochTime=1.34465s
NcclComm: disabled, at least one rank using CPU device
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:20: Final Results: Minibatch[1-8]: CE = 0.05161014 * 100; pixelwiseError = 0.49910714 * 100; miouError = 0.66590059 * 1
12/12/2017 15:02:20: Finished Epoch[ 2 of 2]: [Validate] CE = 0.05161014 * 100; pixelwiseError = 0.49910714 * 100; miouError = 0.66590059 * 1
12/12/2017 15:02:20: Best epoch per criterion so far: [Validate] CE = 0.051610 (Epoch 2); pixelwiseError = 0.499107 (Epoch 2); miouError = 0.665901 (Epoch 2)
12/12/2017 15:02:20: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN8_train'
12/12/2017 15:02:20: Best epoch for criterion 'CE' is 2 and model /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN8_train copied to /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN8_train_CE
12/12/2017 15:02:20: Best epoch for criterion 'miouError' is 2 and model /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN8_train copied to /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN8_train_miouError
12/12/2017 15:02:20: Best epoch for criterion 'pixelwiseError' is 2 and model /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN8_train copied to /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN8_train_pixelwiseError

12/12/2017 15:02:20: Action "train" complete.


12/12/2017 15:02:20: ##############################################################################
12/12/2017 15:02:20: #                                                                            #
12/12/2017 15:02:20: # ConvertFCN8ToFCN4 command (edit action)                                    #
12/12/2017 15:02:20: #                                                                            #
12/12/2017 15:02:20: ##############################################################################

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 40 x 40 x 2, Output: 4 x 4 x 2, Kernel: 16 x 16 x 2, Map: 2, Stride: 8 x 8 x 8, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.

12/12/2017 15:02:20: Action "edit" complete.


12/12/2017 15:02:20: ##############################################################################
12/12/2017 15:02:20: #                                                                            #
12/12/2017 15:02:20: # TrainFCN4 command (train action)                                           #
12/12/2017 15:02:20: #                                                                            #
12/12/2017 15:02:20: ##############################################################################

12/12/2017 15:02:20: 
Creating virgin network.
Load: Loading model file: /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_initial
Post-processing network...

4 roots:
	ignoreMask = InputValue()
	labels = InputValue()
	predictionFCN8 = Convolution()
	upsampledFCN8.W = LearnableParameter()

Validating network. 62 nodes to process in pass 1.

Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *3]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *3]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *3]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *3] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *3] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *3] -> [7 x 7 x 16 x *3]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *3], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *3], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 2 x *3]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [16 x 16 x 2 x 2]

Validating network. 21 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.


Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 114 nodes to process in pass 1.

Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *2]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *2] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *2] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *2] -> [7 x 7 x 16 x *2]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *2], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *2], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 2 x *2]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *2] -> [10 x 10 x 2 x *2]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *2] -> [7 x 7 x 2 x *2]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *2], [7 x 7 x 2 x *2] -> [7 x 7 x 2 x *2]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *2], [7 x 7 x 2 x *2] -> [7 x 7 x 2 x *2]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *2] -> [32 x 32 x 2 x *2]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *2]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *2], [28 x 28 x 2 x *2], [28 x 28 x 1 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *2]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *2] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *2] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *2] -> [784 x 2 x *2]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *2] -> [1 x 2 x *2]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *2] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *2] -> [784 x 2 x *2]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *2] -> [1 x 2 x *2]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *2] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *2] -> [1 x *2]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *2] -> [1 x *2]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *2] -> [1 x *2]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *2], [1 x *2] -> [1 x *2]

Validating network. 68 nodes to process in pass 2.


Validating network, final pass.

upsampledFCN8: using GEMM convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using GEMM convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

12/12/2017 15:02:20: 
Model has 114 nodes. Using CPU.

12/12/2017 15:02:20: Training criterion:   CE = ElementTimes

12/12/2017 15:02:20: Evaluation criteria:
12/12/2017 15:02:20: 	pixelwiseError = ElementTimes
12/12/2017 15:02:20: 	miouError = Minus


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 14 are aliased.
	cropFCN8 (gradient) reuses fusionFCN4 (gradient)
	featuresFCN8.x.b (gradient) reuses featuresFCN8.x.p (gradient)
	CE.log_sum.r (gradient) reuses CE.diff (gradient)
	featuresFCN8.b (gradient) reuses featuresFCN8.p (gradient)
	miouError.u (gradient) reuses miouError.reciprocalUnion.z (gradient)
	miouError.union (gradient) reuses miouError.unionFlat (gradient)
	featuresFCN8.x.s (gradient) reuses featuresFCN8.x.p (gradient)
	miouError.union.MinusArgs[0] (gradient) reuses miouError.unionFlat (gradient)

Memory Sharing: Out of 171 matrices, 106 are shared as 29, and 65 are not shared.

Here are the ones that share memory:
	{ CE.diff : [28 x 28 x 1 x *2]
	  featuresFCN8.x.r : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16] (gradient)
	  predictionFCN4 : [7 x 7 x 2 x *2] (gradient) }
	{ featuresFCN4.x : [14 x 14 x 16 x *2] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *2]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *2] (gradient)
	  upsampledFCN4 : [32 x 32 x 2 x *2] }
	{ featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  out : [28 x 28 x 2 x *2] }
	{ CE.diff_valid : [28 x 28 x 1 x *2] (gradient)
	  CE.logits.r : [28 x 28 x 1 x *2]
	  CE.logits_per_class : [28 x 28 x 2 x *2] (gradient)
	  featuresFCN4 : [7 x 7 x 16 x *2] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  miouError.intersectionFlat : [784 x 2 x *2]
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *2]
	  miouError.unionFlat : [784 x 2 x *2]
	  out : [28 x 28 x 2 x *2] (gradient)
	  pixelwiseError.acc._ : [28 x 28 x 2 x *2] }
	{ featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  predictionFCN4 : [7 x 7 x 2 x *2]
	  predictionFCN8 : [4 x 4 x 2 x *2] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  upsampledFCN8 : [10 x 10 x 2 x *2] }
	{ miouError.reciprocalUnion : [1 x 2]
	  miouError.u : [1 x 2] }
	{ CE.logits_per_class : [28 x 28 x 2 x *2]
	  miouError.outHardmax.isMax : [28 x 28 x 2 x *2] }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *2] }
	{ CE.ce_unnorm : [1] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  miouError.iou : [1 x 2]
	  miouError.miou : [1]
	  miouError.reciprocalUnion.z : [1 x 2] }
	{ miouError.intersectionByClass.r : [1 x 2 x *2]
	  pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *2] }
	{ featuresFCN8.b.x : [4 x 4 x 16 x *2]
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *2]
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN8.x.b.x._ : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *2] }
	{ featuresFCN8 : [4 x 4 x 16 x *2]
	  featuresFCN8.b : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN8.x.b.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *2] }
	{ featuresFCN8.b.x._ : [4 x 4 x 16 x *2]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN8.x.r : [4 x 4 x 16 x *2]
	  featuresFCN8.x.s : [4 x 4 x 16 x *2]
	  featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1] (gradient) }
	{ CE.out_max.r : [28 x 28 x 1 x *2]
	  featuresFCN8.b : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.b.x : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.p : [4 x 4 x 16 x *2]
	  featuresFCN8.p : [4 x 4 x 16 x *2] (gradient)
	  upsampledFCN8 : [10 x 10 x 2 x *2] (gradient) }
	{ featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *2] }
	{ fusionFCN4 : [7 x 7 x 2 x *2]
	  predictionFCN8.W : [2 x 16] (gradient) }
	{ CE.logits.r : [28 x 28 x 1 x *2] (gradient)
	  CE.out_shift : [28 x 28 x 2 x *2] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  miouError.intersection : [28 x 28 x 2 x *2]
	  pixelwiseError.acc.r : [28 x 28 x 1 x *2] }
	{ CE.norm_factor.z : [1]
	  miouError.i : [1 x 2] }
	{ cropFCN8 : [7 x 7 x 2 x *2]
	  upsampledFCN8.W : [4 x 4 x 2 x 2] (gradient) }
	{ CE.log_sum.r : [28 x 28 x 1 x *2]
	  CE.out_max.r : [28 x 28 x 1 x *2] (gradient)
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }
	{ miouError.unionByClass.r : [1 x 2 x *2]
	  pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *2] }
	{ CE.diff : [28 x 28 x 1 x *2] (gradient)
	  CE.log_sum.r : [28 x 28 x 1 x *2] (gradient)
	  cropFCN8 : [7 x 7 x 2 x *2] (gradient)
	  featuresFCN8 : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  fusionFCN4 : [7 x 7 x 2 x *2] (gradient)
	  pixelwiseError.diffs : [28 x 28 x 1 x *2]
	  pixelwiseError.pixelNorm.z.r : [1 x *2] }
	{ featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN4.x : [14 x 14 x 16 x *2] }
	{ CE.out_shift : [28 x 28 x 2 x *2]
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *2] (gradient)
	  upsampledFCN4 : [32 x 32 x 2 x *2] (gradient) }
	{ CE.diff_valid : [28 x 28 x 1 x *2]
	  miouError.union : [28 x 28 x 2 x *2]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *2] }

Here are the ones that don't share memory:
	{miouError.norm : [1]}
	{predictionFCN4.W : [2 x 16]}
	{featuresFCN4.x._.x.c : [14 x 14 x 16 x *2]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)}
	{featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *2]}
	{featuresFCN4 : [7 x 7 x 16 x *2]}
	{CE : [1] (gradient)}
	{miouError.iouSum.r : [1]}
	{pixelwiseError.pixelNorm : [1 x *2]}
	{CE.ce_unnorm : [1]}
	{predictionFCN4.W : [2 x 16] (gradient)}
	{miouError.outMasked : [28 x 28 x 2 x *2]}
	{pixelwiseError.errSum.r : [1 x *2]}
	{CE.norm_factor : [1]}
	{miouError.labelMasked : [28 x 28 x 2 x *2]}
	{featuresFCN8.x.b.x : [4 x 4 x 16 x *2]}
	{miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *2]}
	{pixelwiseError : [1 x *2]}
	{miouError.norm.z : [1]}
	{CE : [1]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{miouError : [1]}
	{BS.Constants.One : [1]}
	{upsampledFCN4.W : [8 x 8 x 2 x 2]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{features : [28 x 28 x 1 x *2]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{upsampledFCN8.W : [4 x 4 x 2 x 2]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{ignoreMask : [28 x 28 x 1 x *2]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{labels : [28 x 28 x 2 x *2]}
	{predictionFCN8.W : [2 x 16]}


12/12/2017 15:02:20: Training 10576 parameters in 21 out of 21 parameter tensors and 57 nodes with gradient:

12/12/2017 15:02:20: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [7 x 7 x 1 x 16]
12/12/2017 15:02:20: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/12/2017 15:02:20: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/12/2017 15:02:20: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/12/2017 15:02:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/12/2017 15:02:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) : [1 x 1 x 16 x 16]
12/12/2017 15:02:20: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/12/2017 15:02:20: 	Node 'predictionFCN4.W' (LearnableParameter operation) : [2 x 16]
12/12/2017 15:02:20: 	Node 'predictionFCN8.W' (LearnableParameter operation) : [2 x 16]
12/12/2017 15:02:20: 	Node 'upsampledFCN8.W' (LearnableParameter operation) : [4 x 4 x 2 x 2]

Initializing dataParallelSGD with FP32 aggregation.
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:20: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/12/2017 15:02:20: Starting Epoch 1: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

12/12/2017 15:02:20: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
12/12/2017 15:02:20:  Epoch[ 1 of 2]-Minibatch[   1-   1]: CE = 0.05408936 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.69100636 * 1; time = 0.0966s; samplesPerSecond = 165.7
12/12/2017 15:02:20:  Epoch[ 1 of 2]-Minibatch[   2-   2]: CE = 0.05386140 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.69340467 * 1; time = 0.0190s; samplesPerSecond = 841.2
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[   3-   3]: CE = 0.05385964 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.69396067 * 1; time = 0.0195s; samplesPerSecond = 822.6
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[   4-   4]: CE = 0.05368596 * 16; pixelwiseError = 0.49896365 * 16; miouError = 0.69347030 * 1; time = 0.0197s; samplesPerSecond = 810.8
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[   5-   5]: CE = 0.05405390 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.69375902 * 1; time = 0.0196s; samplesPerSecond = 817.6
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[   6-   6]: CE = 0.05423409 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.69405001 * 1; time = 0.0194s; samplesPerSecond = 823.2
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[   7-   7]: CE = 0.05287284 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.69366038 * 1; time = 0.0203s; samplesPerSecond = 787.0
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[   8-   8]: CE = 0.05354838 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.69345737 * 1; time = 0.0193s; samplesPerSecond = 827.6
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[   9-   9]: CE = 0.05235602 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.69275916 * 1; time = 0.0196s; samplesPerSecond = 817.2
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  10-  10]: CE = 0.05295735 * 16; pixelwiseError = 0.49888393 * 16; miouError = 0.69204277 * 1; time = 0.0188s; samplesPerSecond = 849.0
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  11-  11]: CE = 0.05347623 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.69193047 * 1; time = 0.0207s; samplesPerSecond = 772.8
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  12-  12]: CE = 0.05425411 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.69224602 * 1; time = 0.0201s; samplesPerSecond = 795.4
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  13-  13]: CE = 0.05330576 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.69225895 * 1; time = 0.0189s; samplesPerSecond = 846.3
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  14-  14]: CE = 0.05264129 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.69169903 * 1; time = 0.0195s; samplesPerSecond = 822.6
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  15-  15]: CE = 0.05210591 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.69132245 * 1; time = 0.0191s; samplesPerSecond = 838.7
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  16-  16]: CE = 0.05206337 * 16; pixelwiseError = 0.50135523 * 16; miouError = 0.69083959 * 1; time = 0.0192s; samplesPerSecond = 832.3
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  17-  17]: CE = 0.05233854 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.69061589 * 1; time = 0.0188s; samplesPerSecond = 851.1
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  18-  18]: CE = 0.05247695 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.69038880 * 1; time = 0.0190s; samplesPerSecond = 844.0
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  19-  19]: CE = 0.05215603 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.68994540 * 1; time = 0.0204s; samplesPerSecond = 785.4
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  20-  20]: CE = 0.05162426 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.68971920 * 1; time = 0.0191s; samplesPerSecond = 836.7
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  21-  21]: CE = 0.05161475 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.68927515 * 1; time = 0.0202s; samplesPerSecond = 793.9
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  22-  22]: CE = 0.05166212 * 16; pixelwiseError = 0.49896365 * 16; miouError = 0.68871164 * 1; time = 0.0194s; samplesPerSecond = 825.3
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  23-  23]: CE = 0.05194612 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68856966 * 1; time = 0.0196s; samplesPerSecond = 815.0
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  24-  24]: CE = 0.05064974 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.68824291 * 1; time = 0.0194s; samplesPerSecond = 824.2
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  25-  25]: CE = 0.05066165 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.68765527 * 1; time = 0.0193s; samplesPerSecond = 827.5
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  26-  26]: CE = 0.05086620 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.68713629 * 1; time = 0.0200s; samplesPerSecond = 801.2
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  27-  27]: CE = 0.05032233 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.68656534 * 1; time = 0.0193s; samplesPerSecond = 829.7
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  28-  28]: CE = 0.05003534 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.68584824 * 1; time = 0.0188s; samplesPerSecond = 853.3
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  29-  29]: CE = 0.05032306 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.68525255 * 1; time = 0.0196s; samplesPerSecond = 815.3
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  30-  30]: CE = 0.05034661 * 16; pixelwiseError = 0.50119579 * 16; miouError = 0.68489790 * 1; time = 0.0197s; samplesPerSecond = 812.7
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  31-  31]: CE = 0.05042352 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.68453825 * 1; time = 0.0203s; samplesPerSecond = 788.2
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  32-  32]: CE = 0.04998004 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.68396288 * 1; time = 0.0256s; samplesPerSecond = 624.0
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  33-  33]: CE = 0.04988796 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68333530 * 1; time = 0.0193s; samplesPerSecond = 830.3
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  34-  34]: CE = 0.04989076 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68268287 * 1; time = 0.0207s; samplesPerSecond = 771.4
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  35-  35]: CE = 0.04950384 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.68214643 * 1; time = 0.0202s; samplesPerSecond = 792.5
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  36-  36]: CE = 0.04935846 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.68156064 * 1; time = 0.0190s; samplesPerSecond = 841.0
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  37-  37]: CE = 0.04955861 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.68087626 * 1; time = 0.0196s; samplesPerSecond = 815.8
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  38-  38]: CE = 0.04900077 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.68023568 * 1; time = 0.0203s; samplesPerSecond = 788.9
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  39-  39]: CE = 0.04891401 * 16; pixelwiseError = 0.50127548 * 16; miouError = 0.67955756 * 1; time = 0.0197s; samplesPerSecond = 814.0
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  40-  40]: CE = 0.04941796 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67893904 * 1; time = 0.0198s; samplesPerSecond = 807.3
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  41-  41]: CE = 0.04927976 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67836642 * 1; time = 0.0259s; samplesPerSecond = 618.9
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  42-  42]: CE = 0.04905720 * 16; pixelwiseError = 0.49856505 * 16; miouError = 0.67784536 * 1; time = 0.0199s; samplesPerSecond = 805.3
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  43-  43]: CE = 0.04904863 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67723703 * 1; time = 0.0195s; samplesPerSecond = 820.2
12/12/2017 15:02:21:  Epoch[ 1 of 2]-Minibatch[  44-  44]: CE = 0.04888812 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67673612 * 1; time = 0.0192s; samplesPerSecond = 835.3
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  45-  45]: CE = 0.04921457 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.67626548 * 1; time = 0.2199s; samplesPerSecond = 72.8
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  46-  46]: CE = 0.04886921 * 16; pixelwiseError = 0.49760842 * 16; miouError = 0.67585838 * 1; time = 0.0197s; samplesPerSecond = 810.2
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  47-  47]: CE = 0.04896325 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.67539454 * 1; time = 0.0200s; samplesPerSecond = 799.7
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  48-  48]: CE = 0.04925600 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67490745 * 1; time = 0.0217s; samplesPerSecond = 738.5
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  49-  49]: CE = 0.04920708 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67444837 * 1; time = 0.0194s; samplesPerSecond = 826.6
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  50-  50]: CE = 0.04889712 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67408592 * 1; time = 0.0194s; samplesPerSecond = 823.2
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  51-  51]: CE = 0.04893032 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67370051 * 1; time = 0.0211s; samplesPerSecond = 757.4
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  52-  52]: CE = 0.04907028 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67328346 * 1; time = 0.0199s; samplesPerSecond = 803.2
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  53-  53]: CE = 0.04876285 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67292869 * 1; time = 0.0190s; samplesPerSecond = 844.0
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  54-  54]: CE = 0.04880419 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67260623 * 1; time = 0.0196s; samplesPerSecond = 815.6
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  55-  55]: CE = 0.04883881 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67225981 * 1; time = 0.0230s; samplesPerSecond = 695.6
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  56-  56]: CE = 0.04879871 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67195857 * 1; time = 0.0194s; samplesPerSecond = 822.8
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  57-  57]: CE = 0.04886726 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.67162782 * 1; time = 0.0196s; samplesPerSecond = 814.7
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  58-  58]: CE = 0.04896034 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.67134053 * 1; time = 0.0203s; samplesPerSecond = 788.0
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  59-  59]: CE = 0.04855657 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67108625 * 1; time = 0.0195s; samplesPerSecond = 821.2
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  60-  60]: CE = 0.04910370 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.67081773 * 1; time = 0.0208s; samplesPerSecond = 771.0
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  61-  61]: CE = 0.04917110 * 16; pixelwiseError = 0.50047827 * 16; miouError = 0.67052513 * 1; time = 0.0197s; samplesPerSecond = 810.8
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  62-  62]: CE = 0.04896231 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67026627 * 1; time = 0.0193s; samplesPerSecond = 827.5
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  63-  63]: CE = 0.09795179 * 8; pixelwiseError = 0.50159436 * 8; miouError = 0.67015606 * 1; time = 0.0180s; samplesPerSecond = 445.5
12/12/2017 15:02:22:  Epoch[ 1 of 2]-Minibatch[  64-  64]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.67015606 * 1; time = 0.0003s; samplesPerSecond = 0.0
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:22: Finished Epoch[ 1 of 2]: [Training] CE = 0.05108494 * 1000; pixelwiseError = 0.49989412 * 1000; miouError = 0.67015606 * 1; totalSamplesSeen = 1000; learningRatePerSample = 0.0099999998; epochTime=1.55223s
NcclComm: disabled, at least one rank using CPU device
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:22: Final Results: Minibatch[1-8]: CE = 0.05616447 * 100; pixelwiseError = 0.50025508 * 100; miouError = 0.67410815 * 1
12/12/2017 15:02:22: Finished Epoch[ 1 of 2]: [Validate] CE = 0.05616447 * 100; pixelwiseError = 0.50025508 * 100; miouError = 0.67410815 * 1
12/12/2017 15:02:22: Best epoch per criterion so far: [Validate] CE = 0.056164 (Epoch 1); pixelwiseError = 0.500255 (Epoch 1); miouError = 0.674108 (Epoch 1)
12/12/2017 15:02:22: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_train.1'

12/12/2017 15:02:22: Starting Epoch 2: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

12/12/2017 15:02:22: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[   1-   1, 0.00%]: CE = 0.04874096 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67050052 * 1; time = 0.0257s; samplesPerSecond = 622.8
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[   2-   2, 0.00%]: CE = 0.04858369 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.67125404 * 1; time = 0.0205s; samplesPerSecond = 779.9
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[   3-   3, 0.00%]: CE = 0.04862259 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67128766 * 1; time = 0.0203s; samplesPerSecond = 788.7
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[   4-   4, 0.00%]: CE = 0.04852108 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67102313 * 1; time = 0.0196s; samplesPerSecond = 816.4
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[   5-   5, 0.00%]: CE = 0.04924865 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67142981 * 1; time = 0.0200s; samplesPerSecond = 798.7
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[   6-   6, 0.00%]: CE = 0.04842536 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67119980 * 1; time = 0.0196s; samplesPerSecond = 818.1
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[   7-   7, 0.00%]: CE = 0.04870931 * 16; pixelwiseError = 0.50095659 * 16; miouError = 0.67143345 * 1; time = 0.0193s; samplesPerSecond = 829.7
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[   8-   8, 0.00%]: CE = 0.04856214 * 16; pixelwiseError = 0.50103635 * 16; miouError = 0.67162758 * 1; time = 0.0193s; samplesPerSecond = 827.8
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[   9-   9, 0.00%]: CE = 0.04851814 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67175072 * 1; time = 0.0193s; samplesPerSecond = 830.1
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  10-  10, 0.00%]: CE = 0.04858113 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67184776 * 1; time = 0.0214s; samplesPerSecond = 747.0
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  11-  11, 0.00%]: CE = 0.04842678 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.67186964 * 1; time = 0.0210s; samplesPerSecond = 761.8
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  12-  12, 0.00%]: CE = 0.04870806 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67206889 * 1; time = 0.0301s; samplesPerSecond = 532.2
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  13-  13, 0.00%]: CE = 0.04835916 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.67224443 * 1; time = 0.0196s; samplesPerSecond = 817.8
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  14-  14, 0.00%]: CE = 0.04857220 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.67253214 * 1; time = 0.0216s; samplesPerSecond = 741.1
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  15-  15, 0.00%]: CE = 0.04875072 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67261362 * 1; time = 0.0195s; samplesPerSecond = 818.7
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  16-  16, 0.00%]: CE = 0.04838095 * 16; pixelwiseError = 0.50063771 * 16; miouError = 0.67275250 * 1; time = 0.0230s; samplesPerSecond = 696.8
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  17-  17, 0.00%]: CE = 0.04791708 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.67269719 * 1; time = 0.0221s; samplesPerSecond = 722.9
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  18-  18, 0.00%]: CE = 0.04792629 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67268026 * 1; time = 0.0204s; samplesPerSecond = 784.5
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  19-  19, 0.00%]: CE = 0.04791694 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67262954 * 1; time = 0.0192s; samplesPerSecond = 833.6
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  20-  20, 0.00%]: CE = 0.04778204 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67264670 * 1; time = 0.0378s; samplesPerSecond = 423.4
12/12/2017 15:02:22:  Epoch[ 2 of 2]-Minibatch[  21-  21, 0.00%]: CE = 0.04807528 * 16; pixelwiseError = 0.50095659 * 16; miouError = 0.67282057 * 1; time = 0.0195s; samplesPerSecond = 819.8
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  22-  22, 0.00%]: CE = 0.04771005 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67289317 * 1; time = 0.0194s; samplesPerSecond = 824.3
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  23-  23, 0.00%]: CE = 0.04764021 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.67300141 * 1; time = 0.0195s; samplesPerSecond = 820.3
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  24-  24, 0.00%]: CE = 0.04776171 * 16; pixelwiseError = 0.50159436 * 16; miouError = 0.67308223 * 1; time = 0.0195s; samplesPerSecond = 822.0
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  25-  25, 0.00%]: CE = 0.04778292 * 16; pixelwiseError = 0.50127548 * 16; miouError = 0.67318410 * 1; time = 0.0194s; samplesPerSecond = 823.5
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  26-  26, 0.00%]: CE = 0.04750795 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67319167 * 1; time = 0.0195s; samplesPerSecond = 819.5
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  27-  27, 0.00%]: CE = 0.04693080 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67311591 * 1; time = 0.0234s; samplesPerSecond = 684.6
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  28-  28, 0.00%]: CE = 0.04714461 * 16; pixelwiseError = 0.50095665 * 16; miouError = 0.67310262 * 1; time = 0.0191s; samplesPerSecond = 838.5
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  29-  29, 0.00%]: CE = 0.04725995 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67307121 * 1; time = 0.0200s; samplesPerSecond = 798.5
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  30-  30, 0.00%]: CE = 0.04727469 * 16; pixelwiseError = 0.49848533 * 16; miouError = 0.67294800 * 1; time = 0.0215s; samplesPerSecond = 743.7
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  31-  31, 0.00%]: CE = 0.04711303 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67284334 * 1; time = 0.0343s; samplesPerSecond = 466.2
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  32-  32, 0.00%]: CE = 0.04695456 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67272663 * 1; time = 0.0198s; samplesPerSecond = 807.2
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  33-  33, 0.00%]: CE = 0.04690164 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67259467 * 1; time = 0.0198s; samplesPerSecond = 807.8
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  34-  34, 0.00%]: CE = 0.04688389 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.67254770 * 1; time = 0.0192s; samplesPerSecond = 834.8
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  35-  35, 0.00%]: CE = 0.04653957 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.67239881 * 1; time = 0.0194s; samplesPerSecond = 824.3
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  36-  36, 0.00%]: CE = 0.04644198 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.67217463 * 1; time = 0.0199s; samplesPerSecond = 803.8
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  37-  37, 0.00%]: CE = 0.04687510 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67208767 * 1; time = 0.0201s; samplesPerSecond = 794.6
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  38-  38, 0.00%]: CE = 0.04662460 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.67191565 * 1; time = 0.0194s; samplesPerSecond = 823.9
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  39-  39, 0.00%]: CE = 0.04632387 * 16; pixelwiseError = 0.49848533 * 16; miouError = 0.67170030 * 1; time = 0.0209s; samplesPerSecond = 766.3
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  40-  40, 0.00%]: CE = 0.04650179 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.67155802 * 1; time = 0.0194s; samplesPerSecond = 824.6
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  41-  41, 0.00%]: CE = 0.04661744 * 16; pixelwiseError = 0.49928254 * 16; miouError = 0.67143220 * 1; time = 0.0198s; samplesPerSecond = 810.0
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  42-  42, 0.00%]: CE = 0.04636549 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67123032 * 1; time = 0.0194s; samplesPerSecond = 823.0
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  43-  43, 0.00%]: CE = 0.04632205 * 16; pixelwiseError = 0.49872449 * 16; miouError = 0.67101586 * 1; time = 0.0201s; samplesPerSecond = 797.4
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  44-  44, 0.00%]: CE = 0.04622598 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.67080575 * 1; time = 0.0217s; samplesPerSecond = 736.6
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  45-  45, 0.00%]: CE = 0.04666368 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67065144 * 1; time = 0.0193s; samplesPerSecond = 829.7
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  46-  46, 0.00%]: CE = 0.04639255 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.67052466 * 1; time = 0.0202s; samplesPerSecond = 792.5
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  47-  47, 0.00%]: CE = 0.04653917 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67040765 * 1; time = 0.0196s; samplesPerSecond = 815.5
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  48-  48, 0.00%]: CE = 0.04647757 * 16; pixelwiseError = 0.49816644 * 16; miouError = 0.67023933 * 1; time = 0.0305s; samplesPerSecond = 525.4
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  49-  49, 0.00%]: CE = 0.04665501 * 16; pixelwiseError = 0.49896365 * 16; miouError = 0.67010105 * 1; time = 0.0202s; samplesPerSecond = 793.9
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  50-  50, 0.00%]: CE = 0.04647039 * 16; pixelwiseError = 0.49912310 * 16; miouError = 0.66996342 * 1; time = 0.0193s; samplesPerSecond = 829.5
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  51-  51, 0.00%]: CE = 0.04623387 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.66985160 * 1; time = 0.0202s; samplesPerSecond = 792.7
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  52-  52, 0.00%]: CE = 0.04638853 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66968668 * 1; time = 0.0203s; samplesPerSecond = 786.3
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  53-  53, 0.00%]: CE = 0.04618937 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66952479 * 1; time = 0.0194s; samplesPerSecond = 824.1
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  54-  54, 0.00%]: CE = 0.04628428 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66939473 * 1; time = 0.0198s; samplesPerSecond = 806.1
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  55-  55, 0.00%]: CE = 0.04640512 * 16; pixelwiseError = 0.49896365 * 16; miouError = 0.66924089 * 1; time = 0.0200s; samplesPerSecond = 798.9
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  56-  56, 0.00%]: CE = 0.04634333 * 16; pixelwiseError = 0.49896365 * 16; miouError = 0.66905093 * 1; time = 0.0200s; samplesPerSecond = 799.5
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  57-  57, 0.00%]: CE = 0.04645073 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66891748 * 1; time = 0.0209s; samplesPerSecond = 766.5
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  58-  58, 0.00%]: CE = 0.04599678 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66880167 * 1; time = 0.0195s; samplesPerSecond = 820.1
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  59-  59, 0.00%]: CE = 0.04626915 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66867828 * 1; time = 0.0205s; samplesPerSecond = 779.8
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  60-  60, 0.00%]: CE = 0.04630078 * 16; pixelwiseError = 0.49880421 * 16; miouError = 0.66854215 * 1; time = 0.0201s; samplesPerSecond = 796.9
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  61-  61, 0.00%]: CE = 0.04631021 * 16; pixelwiseError = 0.49888393 * 16; miouError = 0.66838658 * 1; time = 0.0203s; samplesPerSecond = 788.6
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  62-  62, 0.00%]: CE = 0.04616832 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66827381 * 1; time = 0.0202s; samplesPerSecond = 793.6
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  63-  63, 0.00%]: CE = 0.09348461 * 8; pixelwiseError = 0.50015944 * 8; miouError = 0.66821843 * 1; time = 0.0182s; samplesPerSecond = 440.4
12/12/2017 15:02:23:  Epoch[ 2 of 2]-Minibatch[  64-  64, 0.00%]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.66821843 * 1; time = 0.0003s; samplesPerSecond = 0.0
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:23: Finished Epoch[ 2 of 2]: [Training] CE = 0.04765302 * 1000; pixelwiseError = 0.49989412 * 1000; miouError = 0.66821843 * 1; totalSamplesSeen = 2000; learningRatePerSample = 0.0099999998; epochTime=1.34455s
NcclComm: disabled, at least one rank using CPU device
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:23: Final Results: Minibatch[1-8]: CE = 0.05274211 * 100; pixelwiseError = 0.50051019 * 100; miouError = 0.66819537 * 1
12/12/2017 15:02:23: Finished Epoch[ 2 of 2]: [Validate] CE = 0.05274211 * 100; pixelwiseError = 0.50051019 * 100; miouError = 0.66819537 * 1
12/12/2017 15:02:23: Best epoch per criterion so far: [Validate] CE = 0.052742 (Epoch 2); pixelwiseError = 0.500255 (Epoch 1); miouError = 0.668195 (Epoch 2)
12/12/2017 15:02:23: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_train'
12/12/2017 15:02:23: Best epoch for criterion 'CE' is 2 and model /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_train copied to /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_train_CE
12/12/2017 15:02:23: Best epoch for criterion 'miouError' is 2 and model /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_train copied to /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_train_miouError
12/12/2017 15:02:23: Best epoch for criterion 'pixelwiseError' is 1 and model /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_train.1 copied to /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_train_pixelwiseError

12/12/2017 15:02:23: Action "train" complete.


12/12/2017 15:02:23: ##############################################################################
12/12/2017 15:02:23: #                                                                            #
12/12/2017 15:02:23: # PrepareFCN4ForTest command (edit action)                                   #
12/12/2017 15:02:23: #                                                                            #
12/12/2017 15:02:23: ##############################################################################

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using GEMM convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using GEMM convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.

12/12/2017 15:02:24: Action "edit" complete.


12/12/2017 15:02:24: ##############################################################################
12/12/2017 15:02:24: #                                                                            #
12/12/2017 15:02:24: # TestFCN4 command (test action)                                             #
12/12/2017 15:02:24: #                                                                            #
12/12/2017 15:02:24: ##############################################################################

Load: Loading model file: /tmp/cntk-test-20171211223423.932710/Image_FCN@release_cpu/Models/FCN4_test
Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 114 nodes to process in pass 1.

Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *6]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *6] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *6] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *6] -> [7 x 7 x 16 x *6]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *6], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *6], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 2 x *6]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *6] -> [10 x 10 x 2 x *6]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *6] -> [7 x 7 x 2 x *6]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *6], [7 x 7 x 2 x *6] -> [7 x 7 x 2 x *6]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *6], [7 x 7 x 2 x *6] -> [7 x 7 x 2 x *6]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *6] -> [32 x 32 x 2 x *6]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *6]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *6], [28 x 28 x 2 x *6], [28 x 28 x 1 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *6]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *6] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *6] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *6] -> [784 x 2 x *6]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *6] -> [1 x 2 x *6]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *6] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *6] -> [784 x 2 x *6]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *6] -> [1 x 2 x *6]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *6] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *6] -> [1 x *6]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *6] -> [1 x *6]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *6] -> [1 x *6]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *6], [1 x *6] -> [1 x *6]

Validating network. 68 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using GEMM convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.


Post-processing network...

3 roots:
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 103 nodes to process in pass 1.

Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *5]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *5] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *5] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *5] -> [7 x 7 x 16 x *5]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *5], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *5], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 2 x *5]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *5] -> [10 x 10 x 2 x *5]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *5] -> [7 x 7 x 2 x *5]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *5], [7 x 7 x 2 x *5] -> [7 x 7 x 2 x *5]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *5], [7 x 7 x 2 x *5] -> [7 x 7 x 2 x *5]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *5] -> [32 x 32 x 2 x *5]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *5]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *5], [28 x 28 x 2 x *5], [28 x 28 x 1 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *5]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *5] -> [784 x 2 x *5]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *5] -> [1 x 2 x *5]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *5] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *5] -> [784 x 2 x *5]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *5] -> [1 x 2 x *5]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *5] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *5] -> [1 x *5]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *5] -> [1 x *5]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *5] -> [1 x *5]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *5], [1 x *5] -> [1 x *5]

Validating network. 56 nodes to process in pass 2.


Validating network, final pass.

upsampledFCN8: using GEMM convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using GEMM convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 103 matrices, 53 are shared as 6, and 50 are not shared.

Here are the ones that share memory:
	{ featuresFCN8.b.x : [4 x 4 x 16 x *5]
	  featuresFCN8.p : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.x.p : [4 x 4 x 16 x *5]
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *5]
	  miouError.iou : [1 x 2]
	  miouError.outMasked : [28 x 28 x 2 x *5]
	  miouError.reciprocalUnion.z : [1 x 2]
	  miouError.union : [28 x 28 x 2 x *5]
	  miouError.unionByClass.r : [1 x 2 x *5]
	  pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *5]
	  pixelwiseError.errSum.r : [1 x *5]
	  predictionFCN4 : [7 x 7 x 2 x *5]
	  predictionFCN8 : [4 x 4 x 2 x *5] }
	{ featuresFCN8 : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *5]
	  fusionFCN4 : [7 x 7 x 2 x *5]
	  miouError.intersectionFlat : [784 x 2 x *5]
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *5]
	  miouError.unionFlat : [784 x 2 x *5]
	  pixelwiseError.acc.r : [28 x 28 x 1 x *5]
	  pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *5]
	  pixelwiseError.pixelNorm.z.r : [1 x *5]
	  upsampledFCN8 : [10 x 10 x 2 x *5] }
	{ miouError.i : [1 x 2]
	  miouError.miou : [1] }
	{ featuresFCN4.x : [14 x 14 x 16 x *5]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *5]
	  featuresFCN8.x.r : [4 x 4 x 16 x *5]
	  out : [28 x 28 x 2 x *5]
	  pixelwiseError.acc._ : [28 x 28 x 2 x *5] }
	{ cropFCN8 : [7 x 7 x 2 x *5]
	  featuresFCN4 : [7 x 7 x 16 x *5]
	  miouError.intersection : [28 x 28 x 2 x *5]
	  miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *5]
	  pixelwiseError.diffs : [28 x 28 x 1 x *5]
	  pixelwiseError.pixelNorm : [1 x *5] }
	{ featuresFCN4.x._ : [14 x 14 x 16 x *5]
	  featuresFCN8.b : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *5]
	  featuresFCN8.x.s : [4 x 4 x 16 x *5]
	  miouError.iouSum.r : [1]
	  miouError.labelMasked : [28 x 28 x 2 x *5]
	  miouError.outHardmax.isMax : [28 x 28 x 2 x *5]
	  miouError.reciprocalUnion : [1 x 2]
	  miouError.u : [1 x 2]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *5]
	  upsampledFCN4 : [32 x 32 x 2 x *5] }

Here are the ones that don't share memory:
	{miouError.intersectionByClass.r : [1 x 2 x *5]}
	{BS.Constants.One : [1]}
	{features : [28 x 28 x 1 x *5]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{ignoreMask : [28 x 28 x 1 x *5]}
	{labels : [28 x 28 x 2 x *5]}
	{miouError.norm.z : [1]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{pixelwiseError : [1 x *5]}
	{predictionFCN4.W : [2 x 16]}
	{predictionFCN8.W : [2 x 16]}
	{upsampledFCN4.W : [8 x 8 x 2 x 2]}
	{upsampledFCN8.W : [4 x 4 x 2 x 2]}
	{miouError : [1]}
	{miouError.norm : [1]}

NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:24: Minibatch[1-8]: pixelwiseError = 0.50051020 * 100; miouError = 0.66819537 * 1
NcclComm: disabled, at least one rank using CPU device
12/12/2017 15:02:24: Final Results: Minibatch[1-8]: pixelwiseError = 0.50051020 * 100; miouError = 0.66819543 * 1

12/12/2017 15:02:24: Action "test" complete.

12/12/2017 15:02:24: __COMPLETED__
~MPIWrapperMpi
=== Deleting training and test data