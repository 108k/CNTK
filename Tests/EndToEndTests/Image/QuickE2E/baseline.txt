CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E/cntk.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data RunDir=/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E OutputDir=/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu DeviceId=-1 timestamping=true
CNTK 2.3.1+ (HEAD f4f0f8, Dec 11 2017 18:34:12) at 2017/12/12 15:02:24

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E/cntk.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  RunDir=/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E  OutputDir=/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu  DeviceId=-1  timestamping=true
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Image/Data
12/12/2017 15:02:24: -------------------------------------------------------------------
12/12/2017 15:02:24: Build info: 

12/12/2017 15:02:24: 		Built time: Dec 11 2017 18:28:39
12/12/2017 15:02:24: 		Last modified date: Wed Nov 15 09:27:10 2017
12/12/2017 15:02:24: 		Build type: release
12/12/2017 15:02:24: 		Build target: GPU
12/12/2017 15:02:24: 		With 1bit-SGD: yes
12/12/2017 15:02:24: 		With ASGD: yes
12/12/2017 15:02:24: 		Math lib: mkl
12/12/2017 15:02:24: 		CUDA version: 9.0.0
12/12/2017 15:02:24: 		CUDNN version: 7.0.4
12/12/2017 15:02:24: 		Build Branch: HEAD
12/12/2017 15:02:24: 		Build SHA1: f4f0f82eabcc482dbd03af1f946a44ae2b8b97bf
12/12/2017 15:02:24: 		MPI distribution: Open MPI
12/12/2017 15:02:24: 		MPI version: 1.10.7
12/12/2017 15:02:24: -------------------------------------------------------------------
12/12/2017 15:02:24: -------------------------------------------------------------------
12/12/2017 15:02:24: GPU info:

12/12/2017 15:02:24: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/12/2017 15:02:24: -------------------------------------------------------------------
12/12/2017 15:02:24: Using 6 CPU threads.

12/12/2017 15:02:24: ##############################################################################
12/12/2017 15:02:24: #                                                                            #
12/12/2017 15:02:24: # train command (train action)                                               #
12/12/2017 15:02:24: #                                                                            #
12/12/2017 15:02:24: ##############################################################################

parallelTrain option is not enabled. ParallelTrain config will be ignored.
12/12/2017 15:02:24: 
Creating virgin network.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[128 x 0] as uniform later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[10 x 0] as uniform later when dimensions are fully known.

Post-processing network...

2 roots:
	ce = CrossEntropyWithSoftmax()
	err = ClassificationError()

Validating network. 28 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *]
Validating --> ol.W = LearnableParameter() :  -> [10 x 0]
Validating --> h1.W = LearnableParameter() :  -> [128 x 0]
Validating --> conv2_act.convW = LearnableParameter() :  -> [32 x 400]
Validating --> conv1_act.convW = LearnableParameter() :  -> [16 x 25]
Validating --> featScale = LearnableParameter() :  -> [1 x 1]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *]
Validating --> featScaled = ElementTimes (featScale, features) : [1 x 1], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> conv1_act.conv = Convolution (conv1_act.convW, featScaled) : [16 x 25], [28 x 28 x 1 x *] -> [24 x 24 x 16 x *]
Validating --> conv1_act.convB = LearnableParameter() :  -> [1 x 1 x 16]
Validating --> conv1_act.convPlusB = Plus (conv1_act.conv, conv1_act.convB) : [24 x 24 x 16 x *], [1 x 1 x 16] -> [24 x 24 x 16 x *]
Validating --> conv1_act = RectifiedLinear (conv1_act.convPlusB) : [24 x 24 x 16 x *] -> [24 x 24 x 16 x *]
Validating --> pool1 = MaxPooling (conv1_act) : [24 x 24 x 16 x *] -> [12 x 12 x 16 x *]
Validating --> conv2_act.conv = Convolution (conv2_act.convW, pool1) : [32 x 400], [12 x 12 x 16 x *] -> [8 x 8 x 32 x *]
Validating --> conv2_act.convB = LearnableParameter() :  -> [1 x 1 x 32]
Validating --> conv2_act.convPlusB = Plus (conv2_act.conv, conv2_act.convB) : [8 x 8 x 32 x *], [1 x 1 x 32] -> [8 x 8 x 32 x *]
Validating --> conv2_act = RectifiedLinear (conv2_act.convPlusB) : [8 x 8 x 32 x *] -> [8 x 8 x 32 x *]
Validating --> pool2 = AveragePooling (conv2_act) : [8 x 8 x 32 x *] -> [4 x 4 x 32 x *]
Validating --> h1.x = Reshape (pool2) : [4 x 4 x 32 x *] -> [512 x *]
Node 'h1.W' (LearnableParameter operation) operation: Tensor shape was inferred as [128 x 512].
Node 'h1.W' (LearnableParameter operation): Initializing Parameter[128 x 512] <- uniform(seed=3, init dims=[128 x 512], range=0.050000(0.050000*1.000000), onCPU=true.
)Validating --> h1.z.PlusArgs[0] = Times (h1.W, h1.x) : [128 x 512], [512 x *] -> [128 x *]
Validating --> h1.b = LearnableParameter() :  -> [128]
Validating --> h1.z = Plus (h1.z.PlusArgs[0], h1.b) : [128 x *], [128] -> [128 x *]
Validating --> h1 = Sigmoid (h1.z) : [128 x *] -> [128 x *]
Node 'ol.W' (LearnableParameter operation) operation: Tensor shape was inferred as [10 x 128].
Node 'ol.W' (LearnableParameter operation): Initializing Parameter[10 x 128] <- uniform(seed=5, init dims=[10 x 128], range=0.050000(0.050000*1.000000), onCPU=true.
)Validating --> ol.out.PlusArgs[0] = Times (ol.W, h1) : [10 x 128], [128 x *] -> [10 x *]
Validating --> ol.b = LearnableParameter() :  -> [10 x 1]
Validating --> ol = Plus (ol.out.PlusArgs[0], ol.b) : [10 x *], [10 x 1] -> [10 x 1 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, ol) : [10 x *], [10 x 1 x *] -> [1]
Validating --> err = ClassificationError (labels, ol) : [10 x *], [10 x 1 x *] -> [1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.

12/12/2017 15:02:24: 
Model has 28 nodes. Using CPU.

12/12/2017 15:02:24: Training criterion:   ce = CrossEntropyWithSoftmax
12/12/2017 15:02:24: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 8 are aliased.
	conv1_act.conv (gradient) reuses conv1_act.convPlusB (gradient)
	conv2_act.conv (gradient) reuses conv2_act.convPlusB (gradient)
	pool2 (gradient) reuses h1.x (gradient)
	h1.z.PlusArgs[0] (gradient) reuses h1.z (gradient)

Memory Sharing: Out of 51 matrices, 33 are shared as 9, and 18 are not shared.

Here are the ones that share memory:
	{ conv1_act.conv : [24 x 24 x 16 x *] (gradient)
	  conv1_act.convPlusB : [24 x 24 x 16 x *]
	  conv1_act.convPlusB : [24 x 24 x 16 x *] (gradient)
	  pool1 : [12 x 12 x 16 x *] }
	{ conv2_act.conv : [8 x 8 x 32 x *] (gradient)
	  conv2_act.convPlusB : [8 x 8 x 32 x *] (gradient)
	  h1.x : [512 x *] }
	{ h1.z : [128 x *] (gradient)
	  h1.z.PlusArgs[0] : [128 x *] (gradient)
	  ol.out.PlusArgs[0] : [10 x *]
	  ol.out.PlusArgs[0] : [10 x *] (gradient) }
	{ conv2_act : [8 x 8 x 32 x *]
	  conv2_act.conv : [8 x 8 x 32 x *]
	  pool1 : [12 x 12 x 16 x *] (gradient) }
	{ conv2_act.convW : [32 x 400] (gradient)
	  pool2 : [4 x 4 x 32 x *] }
	{ conv1_act : [24 x 24 x 16 x *]
	  conv1_act.conv : [24 x 24 x 16 x *]
	  conv1_act.convW : [16 x 25] (gradient) }
	{ conv1_act : [24 x 24 x 16 x *] (gradient)
	  conv1_act.convB : [1 x 1 x 16] (gradient)
	  conv2_act : [8 x 8 x 32 x *] (gradient)
	  conv2_act.convPlusB : [8 x 8 x 32 x *]
	  h1 : [128 x *]
	  h1.z.PlusArgs[0] : [128 x *] }
	{ h1.W : [128 x 512] (gradient)
	  ol : [10 x 1 x *] (gradient) }
	{ conv2_act.convB : [1 x 1 x 32] (gradient)
	  h1 : [128 x *] (gradient)
	  h1.x : [512 x *] (gradient)
	  h1.z : [128 x *]
	  ol : [10 x 1 x *]
	  pool2 : [4 x 4 x 32 x *] (gradient) }

Here are the ones that don't share memory:
	{conv1_act.convW : [16 x 25]}
	{h1.W : [128 x 512]}
	{h1.b : [128]}
	{err : [1]}
	{ce : [1] (gradient)}
	{ol.W : [10 x 128] (gradient)}
	{conv2_act.convB : [1 x 1 x 32]}
	{ce : [1]}
	{conv1_act.convB : [1 x 1 x 16]}
	{ol.b : [10 x 1]}
	{features : [28 x 28 x 1 x *]}
	{ol.W : [10 x 128]}
	{labels : [10 x *]}
	{featScale : [1 x 1]}
	{conv2_act.convW : [32 x 400]}
	{h1.b : [128] (gradient)}
	{ol.b : [10 x 1] (gradient)}
	{featScaled : [28 x 28 x 1 x *]}


12/12/2017 15:02:24: Training 80202 parameters in 8 out of 8 parameter tensors and 23 nodes with gradient:

12/12/2017 15:02:24: 	Node 'conv1_act.convB' (LearnableParameter operation) : [1 x 1 x 16]
12/12/2017 15:02:24: 	Node 'conv1_act.convW' (LearnableParameter operation) : [16 x 25]
12/12/2017 15:02:24: 	Node 'conv2_act.convB' (LearnableParameter operation) : [1 x 1 x 32]
12/12/2017 15:02:24: 	Node 'conv2_act.convW' (LearnableParameter operation) : [32 x 400]
12/12/2017 15:02:24: 	Node 'h1.W' (LearnableParameter operation) : [128 x 512]
12/12/2017 15:02:24: 	Node 'h1.b' (LearnableParameter operation) : [128]
12/12/2017 15:02:24: 	Node 'ol.W' (LearnableParameter operation) : [10 x 128]
12/12/2017 15:02:24: 	Node 'ol.b' (LearnableParameter operation) : [10 x 1]

12/12/2017 15:02:24: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/12/2017 15:02:24: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/12/2017 15:02:24: Starting minibatch loop.
12/12/2017 15:02:24:  Epoch[ 1 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.33338428 * 1000; err = 0.90000000 * 1000; time = 0.1428s; samplesPerSecond = 7004.2
12/12/2017 15:02:24: Finished Epoch[ 1 of 5]: [Training] ce = 2.33338428 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 1000; learningRatePerSample = 2e-06; epochTime=0.143324s
12/12/2017 15:02:24: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu/models/cntk.dnn.1'

12/12/2017 15:02:24: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/12/2017 15:02:24: Starting minibatch loop.
12/12/2017 15:02:24:  Epoch[ 2 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.33235547 * 1000; err = 0.90000000 * 1000; time = 0.0950s; samplesPerSecond = 10520.8
12/12/2017 15:02:24: Finished Epoch[ 2 of 5]: [Training] ce = 2.33235547 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 2000; learningRatePerSample = 2e-06; epochTime=0.0956467s
12/12/2017 15:02:24: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu/models/cntk.dnn.2'

12/12/2017 15:02:24: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/12/2017 15:02:24: Starting minibatch loop.
12/12/2017 15:02:24:  Epoch[ 3 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.33108032 * 1000; err = 0.90000000 * 1000; time = 0.0949s; samplesPerSecond = 10534.0
12/12/2017 15:02:24: Finished Epoch[ 3 of 5]: [Training] ce = 2.33108032 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 3000; learningRatePerSample = 2e-06; epochTime=0.095522s
12/12/2017 15:02:24: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu/models/cntk.dnn.3'

12/12/2017 15:02:24: Starting Epoch 4: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/12/2017 15:02:24: Starting minibatch loop.
12/12/2017 15:02:25:  Epoch[ 4 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.32960474 * 1000; err = 0.90000000 * 1000; time = 0.0882s; samplesPerSecond = 11338.5
12/12/2017 15:02:25: Finished Epoch[ 4 of 5]: [Training] ce = 2.32960474 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 4000; learningRatePerSample = 2e-06; epochTime=0.0887658s
12/12/2017 15:02:25: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu/models/cntk.dnn.4'

12/12/2017 15:02:25: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/12/2017 15:02:25: Starting minibatch loop.
12/12/2017 15:02:25:  Epoch[ 5 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.32814014 * 1000; err = 0.90000000 * 1000; time = 0.0881s; samplesPerSecond = 11357.0
12/12/2017 15:02:25: Finished Epoch[ 5 of 5]: [Training] ce = 2.32814014 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 5000; learningRatePerSample = 2e-06; epochTime=0.0890263s
12/12/2017 15:02:25: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu/models/cntk.dnn'

12/12/2017 15:02:25: Action "train" complete.


12/12/2017 15:02:25: ##############################################################################
12/12/2017 15:02:25: #                                                                            #
12/12/2017 15:02:25: # test command (test action)                                                 #
12/12/2017 15:02:25: #                                                                            #
12/12/2017 15:02:25: ##############################################################################

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.
12/12/2017 15:02:25: Final Results: Minibatch[1-1]: err = 0.90000000 * 100; ce = 2.32728577 * 100; perplexity = 10.25008263

12/12/2017 15:02:25: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E/cntk.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data RunDir=/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E OutputDir=/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu DeviceId=-1 timestamping=true makeMode=true
CNTK 2.3.1+ (HEAD f4f0f8, Dec 11 2017 18:34:12) at 2017/12/12 15:02:25

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E/cntk.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  RunDir=/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E  OutputDir=/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu  DeviceId=-1  timestamping=true  makeMode=true
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Image/Data
12/12/2017 15:02:25: -------------------------------------------------------------------
12/12/2017 15:02:25: Build info: 

12/12/2017 15:02:25: 		Built time: Dec 11 2017 18:28:39
12/12/2017 15:02:25: 		Last modified date: Wed Nov 15 09:27:10 2017
12/12/2017 15:02:25: 		Build type: release
12/12/2017 15:02:25: 		Build target: GPU
12/12/2017 15:02:25: 		With 1bit-SGD: yes
12/12/2017 15:02:25: 		With ASGD: yes
12/12/2017 15:02:25: 		Math lib: mkl
12/12/2017 15:02:25: 		CUDA version: 9.0.0
12/12/2017 15:02:25: 		CUDNN version: 7.0.4
12/12/2017 15:02:25: 		Build Branch: HEAD
12/12/2017 15:02:25: 		Build SHA1: f4f0f82eabcc482dbd03af1f946a44ae2b8b97bf
12/12/2017 15:02:25: 		MPI distribution: Open MPI
12/12/2017 15:02:25: 		MPI version: 1.10.7
12/12/2017 15:02:25: -------------------------------------------------------------------
12/12/2017 15:02:25: -------------------------------------------------------------------
12/12/2017 15:02:25: GPU info:

12/12/2017 15:02:25: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/12/2017 15:02:25: -------------------------------------------------------------------
12/12/2017 15:02:25: Using 6 CPU threads.

12/12/2017 15:02:25: ##############################################################################
12/12/2017 15:02:25: #                                                                            #
12/12/2017 15:02:25: # train command (train action)                                               #
12/12/2017 15:02:25: #                                                                            #
12/12/2017 15:02:25: ##############################################################################

parallelTrain option is not enabled. ParallelTrain config will be ignored.
12/12/2017 15:02:25: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu/models/cntk.dnn.4'.
12/12/2017 15:02:25: 
Model has 28 nodes. Using CPU.

12/12/2017 15:02:25: Training criterion:   ce = CrossEntropyWithSoftmax
12/12/2017 15:02:25: Evaluation criterion: err = ClassificationError

12/12/2017 15:02:25: Training 80202 parameters in 8 out of 8 parameter tensors and 23 nodes with gradient:

12/12/2017 15:02:25: 	Node 'conv1_act.convB' (LearnableParameter operation) : [1 x 1 x 16]
12/12/2017 15:02:25: 	Node 'conv1_act.convW' (LearnableParameter operation) : [16 x 25]
12/12/2017 15:02:25: 	Node 'conv2_act.convB' (LearnableParameter operation) : [1 x 1 x 32]
12/12/2017 15:02:25: 	Node 'conv2_act.convW' (LearnableParameter operation) : [32 x 400]
12/12/2017 15:02:25: 	Node 'h1.W' (LearnableParameter operation) : [128 x 512]
12/12/2017 15:02:25: 	Node 'h1.b' (LearnableParameter operation) : [128]
12/12/2017 15:02:25: 	Node 'ol.W' (LearnableParameter operation) : [10 x 128]
12/12/2017 15:02:25: 	Node 'ol.b' (LearnableParameter operation) : [10 x 1]

12/12/2017 15:02:25: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/12/2017 15:02:25: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/12/2017 15:02:25: Starting minibatch loop.
12/12/2017 15:02:25:  Epoch[ 5 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.32814014 * 1000; err = 0.90000000 * 1000; time = 0.1427s; samplesPerSecond = 7007.7
12/12/2017 15:02:25: Finished Epoch[ 5 of 5]: [Training] ce = 2.32814014 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 5000; learningRatePerSample = 2e-06; epochTime=0.143245s
12/12/2017 15:02:25: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Image_QuickE2E@release_cpu/models/cntk.dnn'

12/12/2017 15:02:25: Action "train" complete.


12/12/2017 15:02:25: ##############################################################################
12/12/2017 15:02:25: #                                                                            #
12/12/2017 15:02:25: # test command (test action)                                                 #
12/12/2017 15:02:25: #                                                                            #
12/12/2017 15:02:25: ##############################################################################

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.
12/12/2017 15:02:25: Final Results: Minibatch[1-1]: err = 0.90000000 * 100; ce = 2.32728577 * 100; perplexity = 10.25008263

12/12/2017 15:02:25: __COMPLETED__