CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/GettingStarted/01_OneHidden/../../../../../../Examples/Image/GettingStarted/01_OneHidden.cntk currentDirectory=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST RunDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/GettingStarted_01_OneHidden@release_cpu DataDir=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/GettingStarted/01_OneHidden/../../../../../../Examples/Image/GettingStarted OutputDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/GettingStarted_01_OneHidden@release_cpu DeviceId=-1 timestamping=true forceDeterministicAlgorithms=true stderr=- trainNetwork=[SGD=[maxEpochs=3]]
CNTK 2.3.1+ (HEAD f4f0f8, Dec 11 2017 18:34:12) at 2017/12/12 05:59:06

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/GettingStarted/01_OneHidden/../../../../../../Examples/Image/GettingStarted/01_OneHidden.cntk  currentDirectory=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST  RunDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/GettingStarted_01_OneHidden@release_cpu  DataDir=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/GettingStarted/01_OneHidden/../../../../../../Examples/Image/GettingStarted  OutputDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/GettingStarted_01_OneHidden@release_cpu  DeviceId=-1  timestamping=true  forceDeterministicAlgorithms=true  stderr=-  trainNetwork=[SGD=[maxEpochs=3]]
Changed current directory to /home/ubuntu/workspace/Examples/Image/DataSets/MNIST
12/12/2017 05:59:06: Redirecting stderr to file -_trainNetwork_testNetwork.log
12/12/2017 05:59:06: -------------------------------------------------------------------
12/12/2017 05:59:06: Build info: 

12/12/2017 05:59:06: 		Built time: Dec 11 2017 18:28:39
12/12/2017 05:59:06: 		Last modified date: Wed Nov 15 09:27:10 2017
12/12/2017 05:59:06: 		Build type: release
12/12/2017 05:59:06: 		Build target: GPU
12/12/2017 05:59:06: 		With 1bit-SGD: yes
12/12/2017 05:59:06: 		With ASGD: yes
12/12/2017 05:59:06: 		Math lib: mkl
12/12/2017 05:59:06: 		CUDA version: 9.0.0
12/12/2017 05:59:06: 		CUDNN version: 7.0.4
12/12/2017 05:59:06: 		Build Branch: HEAD
12/12/2017 05:59:06: 		Build SHA1: f4f0f82eabcc482dbd03af1f946a44ae2b8b97bf
12/12/2017 05:59:06: 		MPI distribution: Open MPI
12/12/2017 05:59:06: 		MPI version: 1.10.7
12/12/2017 05:59:06: -------------------------------------------------------------------
12/12/2017 05:59:06: -------------------------------------------------------------------
12/12/2017 05:59:06: GPU info:

12/12/2017 05:59:06: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/12/2017 05:59:06: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: 01_OneHidden.cntk:command=trainNetwork:testNetwork
configparameters: 01_OneHidden.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/GettingStarted/01_OneHidden/../../../../../../Examples/Image/GettingStarted
configparameters: 01_OneHidden.cntk:currentDirectory=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST
configparameters: 01_OneHidden.cntk:dataDir=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST
configparameters: 01_OneHidden.cntk:deviceId=-1
configparameters: 01_OneHidden.cntk:forceDeterministicAlgorithms=true
configparameters: 01_OneHidden.cntk:modelPath=/tmp/cntk-test-20171211223423.932710/Examples/Image/GettingStarted_01_OneHidden@release_cpu/Models/01_OneHidden
configparameters: 01_OneHidden.cntk:outputDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/GettingStarted_01_OneHidden@release_cpu
configparameters: 01_OneHidden.cntk:precision=float
configparameters: 01_OneHidden.cntk:rootDir=..
configparameters: 01_OneHidden.cntk:RunDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/GettingStarted_01_OneHidden@release_cpu
configparameters: 01_OneHidden.cntk:stderr=-
configparameters: 01_OneHidden.cntk:testNetwork={
    action = "test"
minibatchSize = 1024    
    reader = {
        readerType = "CNTKTextFormatReader"
        file = "/home/ubuntu/workspace/Examples/Image/DataSets/MNIST/Test-28x28_cntk_text.txt"
        input = {
            features = { dim = 784 ; format = "dense" }
            labels =   { dim = 10  ; format = "dense" }
        }
    }
}

configparameters: 01_OneHidden.cntk:timestamping=true
configparameters: 01_OneHidden.cntk:traceLevel=1
configparameters: 01_OneHidden.cntk:trainNetwork={
    action = "train"
    BrainScriptNetworkBuilder = {
imageShape = 28:28:1                        
labelDim = 10                               
        featScale = 1/256
        model(x) = {
            s1 = x * featScale
            h1 = DenseLayer {200, activation=ReLU} (s1) 
            z = LinearLayer {labelDim} (h1)
        }
        features = Input {imageShape}
        labels = Input {labelDim}
        out = model (features)
        ce   = CrossEntropyWithSoftmax (labels, out.z)
        errs = ClassificationError (labels, out.z)
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (errs)
        outputNodes     = (out.z)
    }
    SGD = {
        epochSize = 60000
        minibatchSize = 64
        maxEpochs = 10
        learningRatesPerSample = 0.01*5:0.005
        momentumAsTimeConstant = 0
        numMBsToShowResult = 500
    }
    reader = {
        readerType = "CNTKTextFormatReader"
        file = "/home/ubuntu/workspace/Examples/Image/DataSets/MNIST/Train-28x28_cntk_text.txt"
        input = {
            features = { dim = 784 ; format = "dense" }
            labels =   { dim = 10  ; format = "dense" }
        }
    }   
} [SGD=[maxEpochs=3]]

12/12/2017 05:59:06: Commands: trainNetwork testNetwork
12/12/2017 05:59:06: precision = "float"
12/12/2017 05:59:06: WARNING: forceDeterministicAlgorithms flag is specified. Using 1 CPU thread for processing.

12/12/2017 05:59:06: ##############################################################################
12/12/2017 05:59:06: #                                                                            #
12/12/2017 05:59:06: # trainNetwork command (train action)                                        #
12/12/2017 05:59:06: #                                                                            #
12/12/2017 05:59:06: ##############################################################################

12/12/2017 05:59:06: 
Creating virgin network.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[10 x 0] as glorotUniform later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[200 x 0] as glorotUniform later when dimensions are fully known.

Post-processing network...

3 roots:
	ce = CrossEntropyWithSoftmax()
	errs = ClassificationError()
	out.z = Plus()

Validating network. 15 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *]
Validating --> out.z.W = LearnableParameter() :  -> [10 x 0]
Validating --> out.h1.arrayOfFunctions[0].W = LearnableParameter() :  -> [200 x 0]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *]
Validating --> _out.s1 = LearnableParameter() :  -> [1]
Validating --> out.s1 = ElementTimes (features, _out.s1) : [28 x 28 x 1 x *], [1] -> [28 x 28 x 1 x *]
Node 'out.h1.arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [200 x 28 x 28 x 1].
Node 'out.h1.arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[200 x 28 x 28 x 1] <- glorotUniform(seed=2, init dims=[200 x 784], range=0.078087(0.078087*1.000000), onCPU=true.
)Validating --> out.h1._.PlusArgs[0] = Times (out.h1.arrayOfFunctions[0].W, out.s1) : [200 x 28 x 28 x 1], [28 x 28 x 1 x *] -> [200 x *]
Validating --> out.h1.arrayOfFunctions[0].b = LearnableParameter() :  -> [200]
Validating --> out.h1._ = Plus (out.h1._.PlusArgs[0], out.h1.arrayOfFunctions[0].b) : [200 x *], [200] -> [200 x *]
Validating --> out.h1 = RectifiedLinear (out.h1._) : [200 x *] -> [200 x *]
Node 'out.z.W' (LearnableParameter operation) operation: Tensor shape was inferred as [10 x 200].
Node 'out.z.W' (LearnableParameter operation): Initializing Parameter[10 x 200] <- glorotUniform(seed=1, init dims=[10 x 200], range=0.169031(0.169031*1.000000), onCPU=true.
)Validating --> out.z.PlusArgs[0] = Times (out.z.W, out.h1) : [10 x 200], [200 x *] -> [10 x *]
Validating --> out.z.b = LearnableParameter() :  -> [10]
Validating --> out.z = Plus (out.z.PlusArgs[0], out.z.b) : [10 x *], [10] -> [10 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, out.z) : [10 x *], [10 x *] -> [1]
Validating --> errs = ClassificationError (labels, out.z) : [10 x *], [10 x *] -> [1]

Validating network. 8 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.

12/12/2017 05:59:06: 
Model has 15 nodes. Using CPU.

12/12/2017 05:59:06: Training criterion:   ce = CrossEntropyWithSoftmax
12/12/2017 05:59:06: Evaluation criterion: errs = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 4 are aliased.
	out.h1._.PlusArgs[0] (gradient) reuses out.h1._ (gradient)
	out.z.PlusArgs[0] (gradient) reuses out.z (gradient)

Memory Sharing: Out of 25 matrices, 12 are shared as 3, and 13 are not shared.

Here are the ones that share memory:
	{ out.h1 : [200 x *] (gradient)
	  out.h1._ : [200 x *]
	  out.h1.arrayOfFunctions[0].W : [200 x 28 x 28 x 1] (gradient)
	  out.z : [10 x *] }
	{ out.h1._ : [200 x *] (gradient)
	  out.h1._.PlusArgs[0] : [200 x *]
	  out.h1._.PlusArgs[0] : [200 x *] (gradient)
	  out.z : [10 x *] (gradient)
	  out.z.PlusArgs[0] : [10 x *]
	  out.z.PlusArgs[0] : [10 x *] (gradient) }
	{ out.h1 : [200 x *]
	  out.h1.arrayOfFunctions[0].b : [200] (gradient) }

Here are the ones that don't share memory:
	{ce : [1] (gradient)}
	{ce : [1]}
	{errs : [1]}
	{labels : [10 x *]}
	{out.z.b : [10]}
	{out.z.W : [10 x 200] (gradient)}
	{out.z.W : [10 x 200]}
	{out.z.b : [10] (gradient)}
	{out.h1.arrayOfFunctions[0].b : [200]}
	{out.s1 : [28 x 28 x 1 x *]}
	{_out.s1 : [1]}
	{out.h1.arrayOfFunctions[0].W : [200 x 28 x 28 x 1]}
	{features : [28 x 28 x 1 x *]}


12/12/2017 05:59:06: Training 159010 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

12/12/2017 05:59:06: 	Node 'out.h1.arrayOfFunctions[0].W' (LearnableParameter operation) : [200 x 28 x 28 x 1]
12/12/2017 05:59:06: 	Node 'out.h1.arrayOfFunctions[0].b' (LearnableParameter operation) : [200]
12/12/2017 05:59:06: 	Node 'out.z.W' (LearnableParameter operation) : [10 x 200]
12/12/2017 05:59:06: 	Node 'out.z.b' (LearnableParameter operation) : [10]

12/12/2017 05:59:06: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/12/2017 05:59:06: Starting Epoch 1: learning rate per sample = 0.010000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/12/2017 05:59:06: Starting minibatch loop.
12/12/2017 05:59:09:  Epoch[ 1 of 3]-Minibatch[   1- 500, 53.33%]: ce = 0.30729370 * 32000; errs = 9.516% * 32000; time = 2.2160s; samplesPerSecond = 14440.5
12/12/2017 05:59:10: Finished Epoch[ 1 of 3]: [Training] ce = 0.22713368 * 60000; errs = 6.970% * 60000; totalSamplesSeen = 60000; learningRatePerSample = 0.0099999998; epochTime=3.2617s
12/12/2017 05:59:10: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Examples/Image/GettingStarted_01_OneHidden@release_cpu/Models/01_OneHidden.1'

12/12/2017 05:59:10: Starting Epoch 2: learning rate per sample = 0.010000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/12/2017 05:59:10: Starting minibatch loop.
12/12/2017 05:59:11:  Epoch[ 2 of 3]-Minibatch[   1- 500, 53.33%]: ce = 0.09385866 * 32000; errs = 2.866% * 32000; time = 1.1948s; samplesPerSecond = 26782.3
12/12/2017 05:59:12: Finished Epoch[ 2 of 3]: [Training] ce = 0.09221055 * 60000; errs = 2.833% * 60000; totalSamplesSeen = 120000; learningRatePerSample = 0.0099999998; epochTime=2.25684s
12/12/2017 05:59:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Examples/Image/GettingStarted_01_OneHidden@release_cpu/Models/01_OneHidden.2'

12/12/2017 05:59:12: Starting Epoch 3: learning rate per sample = 0.010000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/12/2017 05:59:12: Starting minibatch loop.
12/12/2017 05:59:13:  Epoch[ 3 of 3]-Minibatch[   1- 500, 53.33%]: ce = 0.06352092 * 32000; errs = 2.047% * 32000; time = 1.3607s; samplesPerSecond = 23518.1
12/12/2017 05:59:14: Finished Epoch[ 3 of 3]: [Training] ce = 0.06382062 * 60000; errs = 2.023% * 60000; totalSamplesSeen = 180000; learningRatePerSample = 0.0099999998; epochTime=2.43584s
12/12/2017 05:59:14: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Examples/Image/GettingStarted_01_OneHidden@release_cpu/Models/01_OneHidden'

12/12/2017 05:59:14: Action "train" complete.


12/12/2017 05:59:14: ##############################################################################
12/12/2017 05:59:14: #                                                                            #
12/12/2017 05:59:14: # testNetwork command (test action)                                          #
12/12/2017 05:59:14: #                                                                            #
12/12/2017 05:59:14: ##############################################################################


Post-processing network...

3 roots:
	ce = CrossEntropyWithSoftmax()
	errs = ClassificationError()
	out.z = Plus()

Validating network. 15 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *1]
Validating --> out.z.W = LearnableParameter() :  -> [10 x 200]
Validating --> out.h1.arrayOfFunctions[0].W = LearnableParameter() :  -> [200 x 28 x 28 x 1]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *1]
Validating --> _out.s1 = LearnableParameter() :  -> [1]
Validating --> out.s1 = ElementTimes (features, _out.s1) : [28 x 28 x 1 x *1], [1] -> [28 x 28 x 1 x *1]
Validating --> out.h1._.PlusArgs[0] = Times (out.h1.arrayOfFunctions[0].W, out.s1) : [200 x 28 x 28 x 1], [28 x 28 x 1 x *1] -> [200 x *1]
Validating --> out.h1.arrayOfFunctions[0].b = LearnableParameter() :  -> [200]
Validating --> out.h1._ = Plus (out.h1._.PlusArgs[0], out.h1.arrayOfFunctions[0].b) : [200 x *1], [200] -> [200 x *1]
Validating --> out.h1 = RectifiedLinear (out.h1._) : [200 x *1] -> [200 x *1]
Validating --> out.z.PlusArgs[0] = Times (out.z.W, out.h1) : [10 x 200], [200 x *1] -> [10 x *1]
Validating --> out.z.b = LearnableParameter() :  -> [10]
Validating --> out.z = Plus (out.z.PlusArgs[0], out.z.b) : [10 x *1], [10] -> [10 x *1]
Validating --> ce = CrossEntropyWithSoftmax (labels, out.z) : [10 x *1], [10 x *1] -> [1]
Validating --> errs = ClassificationError (labels, out.z) : [10 x *1], [10 x *1] -> [1]

Validating network. 8 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 15 matrices, 6 are shared as 2, and 9 are not shared.

Here are the ones that share memory:
	{ out.h1._ : [200 x *1]
	  out.s1 : [28 x 28 x 1 x *1]
	  out.z.PlusArgs[0] : [10 x *1] }
	{ out.h1 : [200 x *1]
	  out.h1._.PlusArgs[0] : [200 x *1]
	  out.z : [10 x *1] }

Here are the ones that don't share memory:
	{out.h1.arrayOfFunctions[0].b : [200]}
	{_out.s1 : [1]}
	{labels : [10 x *1]}
	{features : [28 x 28 x 1 x *1]}
	{ce : [1]}
	{out.z.b : [10]}
	{out.z.W : [10 x 200]}
	{errs : [1]}
	{out.h1.arrayOfFunctions[0].W : [200 x 28 x 28 x 1]}

12/12/2017 05:59:15: Minibatch[1-10]: errs = 2.480% * 10000; ce = 0.07631162 * 10000
12/12/2017 05:59:15: Final Results: Minibatch[1-10]: errs = 2.480% * 10000; ce = 0.07631162 * 10000; perplexity = 1.07929886

12/12/2017 05:59:15: Action "test" complete.

12/12/2017 05:59:15: __COMPLETED__