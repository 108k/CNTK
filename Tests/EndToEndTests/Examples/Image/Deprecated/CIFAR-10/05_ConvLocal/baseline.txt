CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal/05_ConvLocal_ndl_deprecated.cntk currentDirectory=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/TestData RunDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu DataDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/TestData ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal OutputDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu DeviceId=-1 timestamping=true Train=[SGD=[maxEpochs=5]] Train=[SGD=[epochSize=100]] stderr=-
CNTK 2.3.1+ (HEAD f4f0f8, Dec 11 2017 18:34:12) at 2017/12/12 05:52:59

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal/05_ConvLocal_ndl_deprecated.cntk  currentDirectory=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/TestData  RunDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu  DataDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/TestData  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal  OutputDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu  DeviceId=-1  timestamping=true  Train=[SGD=[maxEpochs=5]]  Train=[SGD=[epochSize=100]]  stderr=-
Changed current directory to /tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/TestData
12/12/2017 05:52:59: Redirecting stderr to file -_Train_Test.log
12/12/2017 05:52:59: -------------------------------------------------------------------
12/12/2017 05:52:59: Build info: 

12/12/2017 05:52:59: 		Built time: Dec 11 2017 18:28:39
12/12/2017 05:52:59: 		Last modified date: Wed Nov 15 09:27:10 2017
12/12/2017 05:52:59: 		Build type: release
12/12/2017 05:52:59: 		Build target: GPU
12/12/2017 05:52:59: 		With 1bit-SGD: yes
12/12/2017 05:52:59: 		With ASGD: yes
12/12/2017 05:52:59: 		Math lib: mkl
12/12/2017 05:52:59: 		CUDA version: 9.0.0
12/12/2017 05:52:59: 		CUDNN version: 7.0.4
12/12/2017 05:52:59: 		Build Branch: HEAD
12/12/2017 05:52:59: 		Build SHA1: f4f0f82eabcc482dbd03af1f946a44ae2b8b97bf
12/12/2017 05:52:59: 		MPI distribution: Open MPI
12/12/2017 05:52:59: 		MPI version: 1.10.7
12/12/2017 05:52:59: -------------------------------------------------------------------
12/12/2017 05:52:59: -------------------------------------------------------------------
12/12/2017 05:52:59: GPU info:

12/12/2017 05:52:59: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/12/2017 05:52:59: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: 05_ConvLocal_ndl_deprecated.cntk:command=Train:Test
configparameters: 05_ConvLocal_ndl_deprecated.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal
configparameters: 05_ConvLocal_ndl_deprecated.cntk:currentDirectory=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/TestData
configparameters: 05_ConvLocal_ndl_deprecated.cntk:DataDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/TestData
configparameters: 05_ConvLocal_ndl_deprecated.cntk:deviceId=-1
configparameters: 05_ConvLocal_ndl_deprecated.cntk:imageLayout=cudnn
configparameters: 05_ConvLocal_ndl_deprecated.cntk:ModelDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/Models
configparameters: 05_ConvLocal_ndl_deprecated.cntk:modelPath=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/Models/05_ConvLocal
configparameters: 05_ConvLocal_ndl_deprecated.cntk:ndlMacros=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal/../Macros.ndl
configparameters: 05_ConvLocal_ndl_deprecated.cntk:numMBsToShowResult=50
configparameters: 05_ConvLocal_ndl_deprecated.cntk:OutputDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu
configparameters: 05_ConvLocal_ndl_deprecated.cntk:precision=float
configparameters: 05_ConvLocal_ndl_deprecated.cntk:RootDir=.
configparameters: 05_ConvLocal_ndl_deprecated.cntk:RunDir=/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu
configparameters: 05_ConvLocal_ndl_deprecated.cntk:stderr=-
configparameters: 05_ConvLocal_ndl_deprecated.cntk:Test=[
    action = "test"
    minibatchSize = 16
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/TestData/Test_cntk_text.txt"
        input = [
            features = [
                dim = 3072
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]    
]

configparameters: 05_ConvLocal_ndl_deprecated.cntk:timestamping=true
configparameters: 05_ConvLocal_ndl_deprecated.cntk:traceLevel=1
configparameters: 05_ConvLocal_ndl_deprecated.cntk:Train=[
    action = "train"
     NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal/05_ConvLocal.ndl"
    ]
    SGD = [
        epochSize = 49984
        minibatchSize = 64
        learningRatesPerMB = 0.01*10:0.003*10:0.001
        momentumPerMB = 0.9*20:0.99
        maxEpochs = 30
        L2RegWeight = 0.03
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/TestData/Train_cntk_text.txt"
        input = [
            features = [
                dim = 3072
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]    
] [SGD=[maxEpochs=5]] [SGD=[epochSize=100]]

12/12/2017 05:52:59: Commands: Train Test
12/12/2017 05:52:59: precision = "float"

12/12/2017 05:52:59: ##############################################################################
12/12/2017 05:52:59: #                                                                            #
12/12/2017 05:52:59: # Train command (train action)                                               #
12/12/2017 05:52:59: #                                                                            #
12/12/2017 05:52:59: ##############################################################################

12/12/2017 05:52:59: 
Creating virgin network.
NDLBuilder Using CPU
conv1.c: using GEMM convolution engine for geometry: Input: 32 x 32 x 3, Output: 32 x 32 x 64, Kernel: 5 x 5 x 3, Map: 1 x 1 x 64, Stride: 1 x 1 x 3, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
pool1: using GEMM convolution engine for geometry: Input: 32 x 32 x 64, Output: 15 x 15 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv2.c: using GEMM convolution engine for geometry: Input: 15 x 15 x 64, Output: 15 x 15 x 64, Kernel: 5 x 5 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
pool2: using GEMM convolution engine for geometry: Input: 15 x 15 x 64, Output: 7 x 7 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv3.c: using reference convolution engine for geometry, could be VERY SLOW: Input: 7 x 7 x 64, Output: 7 x 7 x 64, Kernel: 3 x 3 x 64, Map: 64, Stride: 1 x 1 x 64, Sharing: (0, 0, 0), AutoPad: (1, 1, 1), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
conv4.c: using reference convolution engine for geometry, could be VERY SLOW: Input: 7 x 7 x 64, Output: 7 x 7 x 32, Kernel: 3 x 3 x 64, Map: 32, Stride: 1 x 1 x 64, Sharing: (0, 0, 0), AutoPad: (1, 1, 1), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
12/12/2017 05:53:00: 
Model has 32 nodes. Using CPU.

12/12/2017 05:53:00: Training criterion:   CE = CrossEntropyWithSoftmax
12/12/2017 05:53:00: Evaluation criterion: Err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 12 are aliased.
	conv1.c (gradient) reuses conv1.p (gradient)
	features (gradient) reuses featScaled (gradient)
	conv3.c (gradient) reuses conv3.p (gradient)
	OutputNodes.t (gradient) reuses OutputNodes.z (gradient)
	conv2.c (gradient) reuses conv2.p (gradient)
	conv4.c (gradient) reuses conv4.p (gradient)

Memory Sharing: Out of 59 matrices, 36 are shared as 7, and 23 are not shared.

Here are the ones that share memory:
	{ conv2.c : [15 x 15 x 64 x *]
	  conv2.c : [15 x 15 x 64 x *] (gradient)
	  conv2.p : [15 x 15 x 64 x *] (gradient)
	  pool2 : [7 x 7 x 64 x *] }
	{ conv3.W : [3136 x 576] (gradient)
	  conv4.y : [7 x 7 x 32 x *] }
	{ conv1.b : [1 x 1 x 64] (gradient)
	  conv1.y : [32 x 32 x 64 x *] }
	{ conv1.W : [64 x 75] (gradient)
	  conv1.p : [32 x 32 x 64 x *]
	  conv1.y : [32 x 32 x 64 x *] (gradient)
	  conv2.y : [15 x 15 x 64 x *] }
	{ OutputNodes.t : [10 x *]
	  OutputNodes.t : [10 x *] (gradient)
	  OutputNodes.z : [10 x *] (gradient)
	  conv2.b : [1 x 1 x 64] (gradient)
	  conv3.c : [7 x 7 x 64 x *] (gradient)
	  conv3.p : [7 x 7 x 64 x *] (gradient)
	  conv4.c : [7 x 7 x 32 x *]
	  conv4.c : [7 x 7 x 32 x *] (gradient)
	  conv4.p : [7 x 7 x 32 x *] (gradient) }
	{ OutputNodes.z : [10 x *]
	  conv2.W : [64 x 1600] (gradient)
	  conv3.p : [7 x 7 x 64 x *]
	  conv3.y : [7 x 7 x 64 x *] (gradient)
	  conv4.p : [7 x 7 x 32 x *]
	  conv4.y : [7 x 7 x 32 x *] (gradient)
	  pool2 : [7 x 7 x 64 x *] (gradient) }
	{ conv1.c : [32 x 32 x 64 x *]
	  conv1.c : [32 x 32 x 64 x *] (gradient)
	  conv1.p : [32 x 32 x 64 x *] (gradient)
	  conv2.p : [15 x 15 x 64 x *]
	  conv2.y : [15 x 15 x 64 x *] (gradient)
	  conv3.c : [7 x 7 x 64 x *]
	  conv3.y : [7 x 7 x 64 x *]
	  pool1 : [15 x 15 x 64 x *] (gradient) }

Here are the ones that don't share memory:
	{features : [32 x 32 x 3 x *]}
	{labels : [10 x *]}
	{featOffs : [1 x 1]}
	{conv1.W : [64 x 75]}
	{conv1.b : [1 x 1 x 64]}
	{conv2.W : [64 x 1600]}
	{conv2.b : [1 x 1 x 64]}
	{conv3.W : [3136 x 576]}
	{conv3.b : [1 x 1 x 64]}
	{conv4.W : [1568 x 576]}
	{conv4.b : [1 x 1 x 32]}
	{OutputNodes.W : [10 x 7 x 7 x 32]}
	{OutputNodes.b : [10]}
	{CE : [1]}
	{Err : [1]}
	{conv3.b : [1 x 1 x 64] (gradient)}
	{OutputNodes.W : [10 x 7 x 7 x 32] (gradient)}
	{conv4.b : [1 x 1 x 32] (gradient)}
	{CE : [1] (gradient)}
	{OutputNodes.b : [10] (gradient)}
	{conv4.W : [1568 x 576] (gradient)}
	{featScaled : [32 x 32 x 3 x *]}
	{pool1 : [15 x 15 x 64 x *]}


12/12/2017 05:53:00: Training 2832618 parameters in 10 out of 10 parameter tensors and 27 nodes with gradient:

12/12/2017 05:53:00: 	Node 'OutputNodes.W' (LearnableParameter operation) : [10 x 7 x 7 x 32]
12/12/2017 05:53:00: 	Node 'OutputNodes.b' (LearnableParameter operation) : [10]
12/12/2017 05:53:00: 	Node 'conv1.W' (LearnableParameter operation) : [64 x 75]
12/12/2017 05:53:00: 	Node 'conv1.b' (LearnableParameter operation) : [1 x 1 x 64]
12/12/2017 05:53:00: 	Node 'conv2.W' (LearnableParameter operation) : [64 x 1600]
12/12/2017 05:53:00: 	Node 'conv2.b' (LearnableParameter operation) : [1 x 1 x 64]
12/12/2017 05:53:00: 	Node 'conv3.W' (LearnableParameter operation) : [3136 x 576]
12/12/2017 05:53:00: 	Node 'conv3.b' (LearnableParameter operation) : [1 x 1 x 64]
12/12/2017 05:53:00: 	Node 'conv4.W' (LearnableParameter operation) : [1568 x 576]
12/12/2017 05:53:00: 	Node 'conv4.b' (LearnableParameter operation) : [1 x 1 x 32]

12/12/2017 05:53:00: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/12/2017 05:53:00: Starting Epoch 1: learning rate per sample = 0.000156  effective momentum = 0.900000  momentum as time constant = 607.4 samples

12/12/2017 05:53:00: Starting minibatch loop.
12/12/2017 05:53:05: Finished Epoch[ 1 of 5]: [Training] CE = 2.30259537 * 100; Err = 0.89000000 * 100; totalSamplesSeen = 100; learningRatePerSample = 0.00015625; epochTime=5.84135s
12/12/2017 05:53:06: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/Models/05_ConvLocal.1'

12/12/2017 05:53:06: Starting Epoch 2: learning rate per sample = 0.000156  effective momentum = 0.900000  momentum as time constant = 607.4 samples

12/12/2017 05:53:06: Starting minibatch loop.
12/12/2017 05:53:08: Finished Epoch[ 2 of 5]: [Training] CE = 2.30256989 * 100; Err = 0.82000000 * 100; totalSamplesSeen = 200; learningRatePerSample = 0.00015625; epochTime=1.81501s
12/12/2017 05:53:08: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/Models/05_ConvLocal.2'

12/12/2017 05:53:08: Starting Epoch 3: learning rate per sample = 0.000156  effective momentum = 0.900000  momentum as time constant = 607.4 samples

12/12/2017 05:53:08: Starting minibatch loop.
12/12/2017 05:53:09: Finished Epoch[ 3 of 5]: [Training] CE = 2.30259399 * 100; Err = 0.89000000 * 100; totalSamplesSeen = 300; learningRatePerSample = 0.00015625; epochTime=1.49904s
12/12/2017 05:53:10: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/Models/05_ConvLocal.3'

12/12/2017 05:53:10: Starting Epoch 4: learning rate per sample = 0.000156  effective momentum = 0.900000  momentum as time constant = 607.4 samples

12/12/2017 05:53:10: Starting minibatch loop.
12/12/2017 05:53:11: Finished Epoch[ 4 of 5]: [Training] CE = 2.30262360 * 100; Err = 0.93000000 * 100; totalSamplesSeen = 400; learningRatePerSample = 0.00015625; epochTime=1.46537s
12/12/2017 05:53:11: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/Models/05_ConvLocal.4'

12/12/2017 05:53:11: Starting Epoch 5: learning rate per sample = 0.000156  effective momentum = 0.900000  momentum as time constant = 607.4 samples

12/12/2017 05:53:11: Starting minibatch loop.
12/12/2017 05:53:13: Finished Epoch[ 5 of 5]: [Training] CE = 2.30256454 * 100; Err = 0.90000000 * 100; totalSamplesSeen = 500; learningRatePerSample = 0.00015625; epochTime=1.65938s
12/12/2017 05:53:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171211223423.932710/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_cpu/Models/05_ConvLocal'

12/12/2017 05:53:13: Action "train" complete.


12/12/2017 05:53:13: ##############################################################################
12/12/2017 05:53:13: #                                                                            #
12/12/2017 05:53:13: # Test command (test action)                                                 #
12/12/2017 05:53:13: #                                                                            #
12/12/2017 05:53:13: ##############################################################################


Post-processing network...

3 roots:
	CE = CrossEntropyWithSoftmax()
	Err = ClassificationError()
	OutputNodes.z = Plus()

Validating network. 32 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *1]
Validating --> OutputNodes.W = LearnableParameter() :  -> [10 x 7 x 7 x 32]
Validating --> conv4.W = LearnableParameter() :  -> [1568 x 576]
Validating --> conv3.W = LearnableParameter() :  -> [3136 x 576]
Validating --> conv2.W = LearnableParameter() :  -> [64 x 1600]
Validating --> conv1.W = LearnableParameter() :  -> [64 x 75]
Validating --> features = InputValue() :  -> [32 x 32 x 3 x *1]
Validating --> featOffs = LearnableParameter() :  -> [1 x 1]
Validating --> featScaled = Minus (features, featOffs) : [32 x 32 x 3 x *1], [1 x 1] -> [32 x 32 x 3 x *1]
Validating --> conv1.c = Convolution (conv1.W, featScaled) : [64 x 75], [32 x 32 x 3 x *1] -> [32 x 32 x 64 x *1]
Validating --> conv1.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv1.p = Plus (conv1.c, conv1.b) : [32 x 32 x 64 x *1], [1 x 1 x 64] -> [32 x 32 x 64 x *1]
Validating --> conv1.y = RectifiedLinear (conv1.p) : [32 x 32 x 64 x *1] -> [32 x 32 x 64 x *1]
Validating --> pool1 = MaxPooling (conv1.y) : [32 x 32 x 64 x *1] -> [15 x 15 x 64 x *1]
Validating --> conv2.c = Convolution (conv2.W, pool1) : [64 x 1600], [15 x 15 x 64 x *1] -> [15 x 15 x 64 x *1]
Validating --> conv2.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv2.p = Plus (conv2.c, conv2.b) : [15 x 15 x 64 x *1], [1 x 1 x 64] -> [15 x 15 x 64 x *1]
Validating --> conv2.y = RectifiedLinear (conv2.p) : [15 x 15 x 64 x *1] -> [15 x 15 x 64 x *1]
Validating --> pool2 = MaxPooling (conv2.y) : [15 x 15 x 64 x *1] -> [7 x 7 x 64 x *1]
Validating --> conv3.c = Convolution (conv3.W, pool2) : [3136 x 576], [7 x 7 x 64 x *1] -> [7 x 7 x 64 x *1]
Validating --> conv3.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv3.p = Plus (conv3.c, conv3.b) : [7 x 7 x 64 x *1], [1 x 1 x 64] -> [7 x 7 x 64 x *1]
Validating --> conv3.y = RectifiedLinear (conv3.p) : [7 x 7 x 64 x *1] -> [7 x 7 x 64 x *1]
Validating --> conv4.c = Convolution (conv4.W, conv3.y) : [1568 x 576], [7 x 7 x 64 x *1] -> [7 x 7 x 32 x *1]
Validating --> conv4.b = LearnableParameter() :  -> [1 x 1 x 32]
Validating --> conv4.p = Plus (conv4.c, conv4.b) : [7 x 7 x 32 x *1], [1 x 1 x 32] -> [7 x 7 x 32 x *1]
Validating --> conv4.y = RectifiedLinear (conv4.p) : [7 x 7 x 32 x *1] -> [7 x 7 x 32 x *1]
Validating --> OutputNodes.t = Times (OutputNodes.W, conv4.y) : [10 x 7 x 7 x 32], [7 x 7 x 32 x *1] -> [10 x *1]
Validating --> OutputNodes.b = LearnableParameter() :  -> [10]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [10 x *1], [10] -> [10 x *1]
Validating --> CE = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [10 x *1], [10 x *1] -> [1]
Validating --> Err = ClassificationError (labels, OutputNodes.z) : [10 x *1], [10 x *1] -> [1]

Validating network. 19 nodes to process in pass 2.


Validating network, final pass.

conv1.c: using GEMM convolution engine for geometry: Input: 32 x 32 x 3, Output: 32 x 32 x 64, Kernel: 5 x 5 x 3, Map: 1 x 1 x 64, Stride: 1 x 1 x 3, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
pool1: using GEMM convolution engine for geometry: Input: 32 x 32 x 64, Output: 15 x 15 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv2.c: using GEMM convolution engine for geometry: Input: 15 x 15 x 64, Output: 15 x 15 x 64, Kernel: 5 x 5 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
pool2: using GEMM convolution engine for geometry: Input: 15 x 15 x 64, Output: 7 x 7 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv3.c: using reference convolution engine for geometry, could be VERY SLOW: Input: 7 x 7 x 64, Output: 7 x 7 x 64, Kernel: 3 x 3 x 64, Map: 64, Stride: 1 x 1 x 64, Sharing: (0, 0, 0), AutoPad: (1, 1, 1), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
conv4.c: using reference convolution engine for geometry, could be VERY SLOW: Input: 7 x 7 x 64, Output: 7 x 7 x 32, Kernel: 3 x 3 x 64, Map: 32, Stride: 1 x 1 x 64, Sharing: (0, 0, 0), AutoPad: (1, 1, 1), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 32 matrices, 17 are shared as 2, and 15 are not shared.

Here are the ones that share memory:
	{ OutputNodes.t : [10 x *1]
	  conv1.c : [32 x 32 x 64 x *1]
	  conv1.y : [32 x 32 x 64 x *1]
	  conv2.c : [15 x 15 x 64 x *1]
	  conv2.y : [15 x 15 x 64 x *1]
	  conv3.c : [7 x 7 x 64 x *1]
	  conv3.y : [7 x 7 x 64 x *1]
	  conv4.p : [7 x 7 x 32 x *1] }
	{ OutputNodes.z : [10 x *1]
	  conv1.p : [32 x 32 x 64 x *1]
	  conv2.p : [15 x 15 x 64 x *1]
	  conv3.p : [7 x 7 x 64 x *1]
	  conv4.c : [7 x 7 x 32 x *1]
	  conv4.y : [7 x 7 x 32 x *1]
	  featScaled : [32 x 32 x 3 x *1]
	  pool1 : [15 x 15 x 64 x *1]
	  pool2 : [7 x 7 x 64 x *1] }

Here are the ones that don't share memory:
	{CE : [1]}
	{conv4.W : [1568 x 576]}
	{featOffs : [1 x 1]}
	{features : [32 x 32 x 3 x *1]}
	{Err : [1]}
	{conv2.W : [64 x 1600]}
	{conv1.b : [1 x 1 x 64]}
	{labels : [10 x *1]}
	{OutputNodes.b : [10]}
	{OutputNodes.W : [10 x 7 x 7 x 32]}
	{conv3.b : [1 x 1 x 64]}
	{conv3.W : [3136 x 576]}
	{conv1.W : [64 x 75]}
	{conv2.b : [1 x 1 x 64]}
	{conv4.b : [1 x 1 x 32]}

12/12/2017 05:53:16: Minibatch[1-50]: Err = 0.89875000 * 800; CE = 2.30256423 * 800
12/12/2017 05:53:17: Minibatch[51-100]: Err = 0.90375000 * 800; CE = 2.30254168 * 800
12/12/2017 05:53:19: Minibatch[101-150]: Err = 0.88625000 * 800; CE = 2.30254756 * 800
12/12/2017 05:53:22: Minibatch[151-200]: Err = 0.88500000 * 800; CE = 2.30253749 * 800
12/12/2017 05:53:24: Minibatch[201-250]: Err = 0.88500000 * 800; CE = 2.30253733 * 800
12/12/2017 05:53:27: Minibatch[251-300]: Err = 0.90875000 * 800; CE = 2.30255357 * 800
12/12/2017 05:53:29: Minibatch[301-350]: Err = 0.91875000 * 800; CE = 2.30254982 * 800
12/12/2017 05:53:33: Minibatch[351-400]: Err = 0.90125000 * 800; CE = 2.30253642 * 800
12/12/2017 05:53:35: Minibatch[401-450]: Err = 0.89375000 * 800; CE = 2.30254367 * 800
12/12/2017 05:53:38: Minibatch[451-500]: Err = 0.88375000 * 800; CE = 2.30254220 * 800
12/12/2017 05:53:41: Minibatch[501-550]: Err = 0.91375000 * 800; CE = 2.30255396 * 800
12/12/2017 05:53:44: Minibatch[551-600]: Err = 0.90125000 * 800; CE = 2.30257049 * 800
12/12/2017 05:53:45: Minibatch[601-625]: Err = 0.89500000 * 400; CE = 2.30253354 * 400
12/12/2017 05:53:45: Final Results: Minibatch[1-625]: Err = 0.89820000 * 10000; CE = 2.30254761 * 10000; perplexity = 9.99962522

12/12/2017 05:53:45: Action "test" complete.

12/12/2017 05:53:45: __COMPLETED__